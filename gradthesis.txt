\chapter{はじめに Introduction}

仮想現実（VR）技術の発展により，ユーザは仮想身体を通じて多様な体験が可能となった．VR研究は，視覚的な忠実度（Fidelity）の追求から，存在することの体験的忠実度，すなわち身体所有感（Sense of Body Ownership: SoBO）や行為主体感（Sense of Agency: SoA）へと焦点が移行してきた~\cite{10.3389/frvir.2023.1141683}．身体化の錯覚（Embodiment Illusion）とは，ユーザが能動的・自発的な運動実行を通じて頭や手足を動かし，脳内の予測状態が感覚入力（視覚，固有受容感覚，聴覚など）から得られる情報と一致したとき生じる強力なVRの錯覚である~\cite{10.3389/fpsyg.2017.01125}．この錯覚の強さは，「私がこの行動の開始者であり源である」という主体感に由来する．身体化感覚（Sense of Embodiment: SoE）の主要な構成要素である身体所有感（SoBO）と行為主体感（SoA）は機能的に分離可能であり~\cite{10.3389/fnhum.2012.00040}，触覚刺激がなくても視覚情報と運動の同期だけで身体所有感は形成される~\cite{10.1371/journal.pone.0010381}．

VR空間における移動（ロコモーション）手法も身体化に影響を与える重要な要素である．従来の研究では，その場歩き（Walking-in-Place）~\cite{10.1145/210079.210084}，コントローラ~\cite{inbook}，テレポート~\cite{10.1145/2967934.2968105}など多様な手法が提案されてきた．その場歩きは固有受容情報と感覚フィードバックの一致により存在感を高め~\cite{10.1145/210079.210084}，腕振り移動はジョイスティックよりも優れた空間認識を提供する~\cite{10.1145/2804408.2804416}．広大な物理空間での自然な歩行はテレポートよりもユーザ体験として優れ，VR酔いも少ない~\cite{10.1109/ISMAR50242.2020.00088}．ここで重要なのは，アバタの可視性と身体化の関係である．VRアクションゲームにおける研究では，多くのVRゲームが消費者向け全身モーションキャプチャデバイスの制約により，浮遊した仮想の手だけでユーザを表現している~\cite{8446229}．興味深いことに，ゲーム文脈では表示される身体部分が増えても身体所有感，没入感，パフォーマンスに有意な差は見られず，見た目よりも「自分の思った通りに手が動くか（主体感）」がより重要であることが示唆されている．移動技術と身体所有感の関係についても，アバタを身体化している場合，どの技術を用いても参加者は同程度の身体所有感を持つことが報告されている~\cite{10.1109/ISMAR50242.2020.00070}．これらの知見は，身体化において視覚的な完全性よりも運動と感覚の同期が本質的に重要であることを示している．

VR技術の進歩に伴い，人間型（擬人化）アバタを超えて，動物，空想上の生物，抽象的な形状など，非人間型の形態への身体化を通じて，人体スキーマの可塑性を探求する研究が進められている~\cite{10.1111/jcc4.12173, 10.1038/s41598-022-05184-0, 10.1145/3611659.3617211}．非人間型アバタには動物だけでなく植物（木など）も含まれ，VRを通じて木の身体化を経験することで没入感や自然との関連性が促進されることが報告されている~\cite{10.1038/s41598-022-05184-0}．動物の身体化に関しては，Ahnらの3つの実験（N=228）で牛やサンゴのアバタを用いてIVE（没入型仮想環境）とビデオを比較し，IVE条件が有意に高い身体転送（body transfer）と自己への自然の包含（INS）をもたらすことが示されている~\cite{10.1111/jcc4.12173}．ペンギンへの身体化研究では，VRでの身体化の強さと体験後の共感度に有意な相関関係が見られ，非人間キャラクターへの身体化が教育や生物への理解促進において強力なツールとなりうることが実証されている~\cite{10.1145/3611659.3617211}．

多様な形態に宿るこの能力は，ユーザが自身のデジタル表現の知覚された特性に合わせて行動や認知を変容させる「プロテウス効果」を誘発する~\cite{10.3389/fpsyg.2017.01125, LAN2023100020, ratan2024proteus}．プロテウス効果のメカニズムについては，没入型VR，仮想環境，およびアバタの使用がユーザに没個性化の感覚を引き起こし，アバタの外見によって喚起される行動的および態度的期待に同調しやすくなるという見解が提案されている~\cite{ratan2024proteus}．また，アバタの外見と行動の不一致を避けようとする認知的不協和の心理が働くとも仮定されている．非人間型アバタにおいてもプロテウス効果が確認されており，魅力的な非人間型アバタを体現した参加者は，自己類似性を通じたアバタへの同一視をより高く知覚し，社会的参加が増加することが示されている~\cite{LAN2023100020}．

しかし，非人間型アバタにおいて強固な身体化感覚を達成するには，人間の運動学を非人間の生体力学にマッピングするという独自の課題が存在する~\cite{10.1145/3544548.3581027, 10.1145/2380116.2380171, 10.1145/2485895.2485903}．動物は関節の数や構造（形態）が人間と異なるため，「人間のどの部位を動物のどの部位に対応させるか」という正解がない~\cite{10.1145/2485895.2485903}．ユーザの手の高い器用さと協調性を活用し，自動生成された関節間マッピングを通じて非ヒューマノイドアバタを制御する手法も提案されている~\cite{10.1145/3544548.3581027}．一方，全身を使って多様な静的メッシュをアニメーション化できるが，全身での非人間アバタ操作は負荷が高いという課題がある~\cite{10.1145/2380116.2380171}．

現在の研究は，非人間型アバタにおける身体化の主要な推進要因として，動作の整合性（Motion Congruence）と身体的姿勢（Physical Posture）の2つを特定している．Khanら（2025）~\cite{11192101}は，アバタの外見と移動方法の間の整合性（congruence）がアバタへの同一視（avatar identification）とユーザ体験を有意に向上させることを実証した．これとは独立して，Krekhovら（2019）~\cite{8848005}は身体的姿勢の重要性を強調し，アバタと整合した姿勢をとることが非人間型であっても強力な身体所有感を引き出せることを示した．


これらの進展にもかかわらず，姿勢と動作の整合性の間の相互作用効果，および入力動作と動作姿勢のロコモーション時の検証が十分ではない．整合的な姿勢をとることは，単に身体化スコアを加算するだけなのか，それとも整合的な動作の認知的効果を増幅させる乗数として機能するのか？本研究では以下の研究課題を設定し，検証する．

\begin{description}
\item[RQ1] 四足歩行動物アバタでのロコモーション環境下において，ユーザの物理的な姿勢（擬似四つん這い VS 立位）および操作のマッピング一致性（動物らしい VS 人間らしい）は，アバタへの自己認識（身体所有感，行為主体感）に影響を与えるか？
\item[RQ2] 四足歩行動物アバタでのロコモーション環境下において，マッピング一致性が自己認識に与える影響の度合いは，ユーザの物理的な姿勢によって変わるか？（擬似四つん這い姿勢において，動物らしい操作の効果が特に強まるか？）
\item[RQ3] 四足歩行動物アバタでのロコモーション環境下において，ユーザの物理的な姿勢やマッピング一致性は，プロテウス効果を増強するか？
\end{description}

Khanら~\cite{11192101}の「整合性」フレームワークとKrekhovら~\cite{8848005}の「姿勢」フレームワークを統合し，両者をクマ科動物の生物学的現実に基づかせることで，非人間型身体化の基礎となるメカニズムについて詳しく検討する．


\chapter{関連研究 Related Work}

\section{人型アバタへの身体化}

VRにおける身体化の錯覚は，脳の予測符号化（Predictive Coding）メカニズムに基づいているとといわれている~\cite{10.3389/fpsyg.2017.01125}．ユーザが能動的・自発的な運動実行を通じて頭や手足を動かし，脳内の予測状態が感覚入力と一致したとき，強力なVRの錯覚が生じる．不一致な感覚入力は，予測された世界の状態を確認するために再調整または抑制され，脳は予測された結果への優先傾向を強化するために感覚入力の方に誤りがあると「決定」することができる．これらのトップダウンの主体感メカニズムは，特定の状況下で遅延（最大200msまで）への許容度を高めることが示されている．

身体化感覚は，身体所有感（SoBO）と行為主体感（SoA）という代表的な2つの構成要素を含む~\cite{guy2023sense}．SoAとSoBOは機能的に分離可能であり，バーチャルな手を不一致な物体に置き換えても，リアルタイムの自発的な動きが保たれていれば潜在的なSoAは維持される~\cite{kalckert2012moving}．参加者は，現実とバーチャルの動きの間の視覚運動整合性が保たれていれば，非身体的な物体に対してさえSoAを経験することができる．また，触覚刺激がなくても，視覚情報と運動の同期だけで身体所有感の錯覚は形成される~\cite{10.1371/journal.pone.0010381}．Sanchez-Vivesらの研究では，180秒間の視覚運動同期刺激の後，仮想の手が20秒かけて約20cm移動したにもかかわらず，被験者は自分の手が動いていないことを知りながらも，手の位置を仮想の手の方向に誤認した．これは，視覚と固有受容感覚が視覚優位で統合されると，視覚的要素の移動が固有受容感覚的要素の移動も引き起こすことを示している．さらに重要な知見として，指の視覚触覚相関は個々の指の錯覚的変位を誘発するのに対し，指の動きの視覚運動相関は腕全体の錯覚的変位を誘発し，より全体的で断片化されていない身体所有感を生成することが報告されている~\cite{10.1371/journal.pone.0010381}．VRにおいて「リアルタイム」かつ「タスクの邪魔にならない」評価手法が身体化の測定において最も重要とされている~\cite{guy2023sense}．

子供と成人を対象とした研究では，動きの同期（視覚運動同期）とアバタの外見が身体所有感と主体感に影響を与えることが確認されている~\cite{weijs2023movement}．動きが遅れる（非同期）ほど，また外見が人間らしくないほど，所有感は減少するが，子供は成人より悪条件の影響を受けにくいことが示されている．アバタの外見のリアリズムと類似性は身体所有感にとって重要であり，ユーザ自身の顔に似たアバタを使用することでEmbodimentとPresenceが促進される~\cite{10.1145/3281505.3281511}．

視点の選択も身体化に影響を与える．一人称視点と三人称視点の比較研究では，ナビゲーションタスクには一人称視点の方が適していることが示されており，三人称視点がリアルな表現と組み合わされたときのみ，一人称視点と同様の身体所有感と空間認識が得られることがわかっている~\cite{10.1177/0956797612462902}．

VR空間内での移動手法は多様化している．従来はコントローラベースの移動が主流であり~\cite{inbook}，主要な手法として，その場歩き（Walking-in-Place），コントローラ，テレポートの3つが存在する~\cite{10.1145/2967934.2968105}．その場歩きは，人間の体の動きから得られる固有受容情報とディスプレイからの感覚フィードバックの一致が強いほど仮想環境での存在感が増すという考えに基づいているといわれている~\cite{10.1145/210079.210084}．腕振り移動は，高価な歩行トラッキングシステムの代わりに安価なウェアラブルデバイスを使用し，ジョイスティックよりも優れた空間認識を提供できる~\cite{10.1145/2804408.2804416}．広大な物理空間での自然な歩行はテレポートよりもユーザ体験として優れており，VR酔いも少ない~\cite{10.1109/ISMAR50242.2020.00088}．移動技術と身体所有感の関係については，アバタを身体化している場合，どの技術を用いても参加者は同程度の身体所有感を持つことが報告されている~\cite{10.1109/ISMAR50242.2020.00070}．マシンを用いたVR移動研究では，頭，手，足の動きに基づいた操縦技術が2Dおよび3D VR環境向けに実装されている~\cite{10.1145/3613904.3642192}．

VR空間におけるアバタが現実の物理法則に従って動くことも，身体所有感に影響を与える~\cite{10.1145/3544548.3580979}．ユーザの動きとの同期（1対1のマッピング）を多少犠牲にしても，環境に対して物理的に正しく反応する方が，VR体験における身体性を向上させることが示されている．物理対応アバタは，単なる身体認識だけでなく，周囲の環境との関係性（Environment Awareness）をユーザに提供する．自己アバタの見た目（リアリズムと身体の可視性）は，ユーザの現実的な振る舞いにも影響し，リアルな全身アバタが参加者の壁抜けを抑制するのに最も効果的であることが示されている~\cite{10.1145/3313831.3376562}．

\section{非人間型アバタへの身体化}

非人間型アバタへの身体化研究は，動物から植物まで多様な形態を対象としている．動物の身体化に関しては，Ahnらによる3つの実験で，牛とサンゴのアバタを用いてIVE（没入型仮想環境）での身体化体験とビデオ視聴を比較した研究がある~\cite{10.1111/jcc4.12173}．実験1では，参加者は四つん這いになり牧草地で牛のアバタを体験し，仮想の電気棒で突かれると同時に床の振動と背中への物理的刺激が触覚フィードバックとして与えられた．結果として，IVE条件はビデオ条件と比較して，より高い空間的実在感（spatial presence, d=.69），身体転送（body transfer, d=.62），および自己への自然の包含（INS, d=.86）を示した．並列媒介分析の結果，3つの実験を通じて一貫してIVE体験とINSの関係を媒介していたのは身体転送のみであり，空間的実在感の媒介効果は実験1では有意でなく，実験2でも1週間後には消失した．植物（木）の身体化研究では，iVRを通じて木の身体化を経験することが没入感，自然との関連性，視点取得，人間と自然の関係についての省察を促進するかが調査されている~\cite{10.1038/s41598-022-05184-0}．参加者が体験に没入していると感じるほど，自然との関連性のレベルが高まることが報告されている．ペンギンへの身体化研究では，VRでの身体化の強さと体験後の共感度に有意な相関関係が見られ，非人間キャラクターへの身体化が教育や生物への理解促進において強力なツールとなりうることが実証されている~\cite{10.1145/3611659.3617211}．

人間以外のキャラクターをリアルタイムに操作するパペトリーシステムでは，身体構造や動作パターンが人間と大きく異なる様々なクリーチャーの制御が試みられている~\cite{10.1145/2485895.2485903}．動物やクリーチャーは関節の数や形態が人間と異なるため，人間とクリーチャー間の身体対応関係の設計は曖昧で非自明なタスクである．直接特徴マッピング手法では最適な人間-クリーチャー間の身体対応関係が選択され，人間が物理的に真似できない動きについてはモーションカップリングが使用される．HandAvatarは，ユーザの手の高い器用さと協調性を活用し，自動生成された関節間マッピングを通じて非ヒューマノイドアバタを制御する手法を提案している~\cite{10.1145/3544548.3581027}．このシステムは，制御精度（F），構造的類似性（S），快適さ（C）の3つの目的関数を重み付けして同時最適化することで，ユーザが優先する要素に応じたマッピングを自動生成する．評価実験では，全身ベースの制御方法と比較して，静的ポーズにおいて40\%，動的アニメーションにおいて25\%の関節偏差削減を達成し，身体化感覚（embodiment）を維持しながらより高い制御精度と快適さを提供することが示された~\cite{10.1145/3544548.3581027}．KinEtreは非専門家ユーザが人間の全身を使って椅子や本棚，はしごなど任意の静的メッシュをリアルタイムにアニメーション化できるシステムであり，非人間型オブジェクトの操作において高い没入感を提供するが，全身でのインタラクションは非常に身体的な活動であり，特に四足動物のように這いつくばる姿勢が必要な場合は著しい疲労を伴う~\cite{10.1145/2380116.2380171}．

Krekhovら（2019）~\cite{10.1145/3313831.3376562}は，仮想の身体所有感の錯覚（IVBO）が非人間型アバタにおいて特に高い潜在能力を持つと仮説を立て，サイ，サソリ，鳥という3種類の動物アバタを用いたエスケープルームゲームで検証した．各ゲームでは動物特有の能力（サイの角，サソリの尾と鋏，鳥の翼）を活用したメカニクスが実装され，32名の参加者による評価の結果，IVBOとゲームの楽しさ，およびプレゼンス感との間に有意な正の相関が確認された．姿勢に関しては，サイでは四つん這いによる1:1マッピング，サソリでは立位によるハーフボディマッピングが採用され，いずれの姿勢も直感的で現実的と評価された．特に，立位でサソリを操作する条件でも，四つん這いでサイを操作する条件と同等のIVBOスコアが得られ，追加の身体パーツ（角，尻尾，翼など）の制御も没入感を損なわないことが示された．

プロテウス効果とは，ユーザが自身のデジタル表現の知覚された特性に合わせて行動や認知を変容させる現象である~\cite{10.3389/fpsyg.2017.01125, 10.1016/j.chbah.2023.100020, ratan2024proteus}．仮想環境において，人々は自分が体現しているバーチャルアバタの特徴に沿った行動をとる傾向がある~\cite{LAN2023100020}．プロテウス効果のメカニズムについては，没入型VRとアバタの使用がユーザに没個性化の感覚を引き起こし，アバタの外見によって喚起される行動的・態度的期待に同調しやすくなるという見解が提案されている~\cite{ratan2024proteus}．また，アバタの外見と行動の不一致を避けようとする認知的不協和の心理も働く~\cite{ratan2024proteus}．非人間型アバタにおいてもプロテウス効果は確認されており，魅力的な非人間型アバタを体現した参加者は，自己類似性を通じたアバタへの同一視をより高く知覚し，社会的参加が増加する~\cite{LAN2023100020}．アバタと環境の適合性に関しては，両者が一致している場合にシミュレーションのもっともらしさ（特に外的整合性）の評価が有意に高まるが，プロテウス効果は環境の違いによって変化せず，自分がどのような姿をしているかが行動変容の要因としてより強力である可能性が示唆されている~\cite{10.1145/3311350.3347172}．身体化やプレゼンスは条件に関わらず全体的に高いスコアを示し，多少の文脈不一致があっても基本的な身体所有感は損なわれない．

\section{姿勢と入力動作の一致性}

非人間型アバタにおける身体化の推進要因として，動作の整合性（Motion Congruence）と身体的姿勢（Physical Posture）が特定されている．本節では，これらの要因に関する2つの重要な先行研究について詳述する．

Khanら（2025）~\cite{11192101}は，アバタの外見と移動方法の整合性（Avatar-Locomotion Congruence）がユーザ体験とアバタへの同一視（avatar identification）に与える影響を調査した．彼らは30名の参加者を対象に被験者内実験を実施し，2種類のアバタ（ゴリラと人間）と2種類の移動方法（ゴリラ的なアームローリングと人間的な腕振り）を用いた．アームローリングは人気のソーシャルVRゲーム「Gorilla Tag」に触発されたもので，ユーザの視点は地面に近く設定され，仮想の手が地面に接触してゴリラの四足歩行を模倣する．ユーザは地面に対して手を引いたり押したりすることで，シミュレートされた力を発生させ運動量を生成する．一方，腕振り移動はパルクールゲーム「Stride」などで使用されており，ユーザの視点はより高く設定され，自然な歩行動作で腕を振ることで移動する．実験の結果，アバタの外見と移動方法が整合している条件（ゴリラ×アームローリング，人間×腕振り）において，アバタへの同一視（wishful identification，embodied presence，similarity identification）とユーザ体験（enjoyment，satisfaction，ease of learning）が有意に向上することが明らかになった．特に，ゴリラアバタとアームローリングの組み合わせは，他の条件と比較して高い楽しさと満足度を示した．また，整合条件では学習のしやすさが向上し，不整合条件（例：ゴリラ×腕振り）ではより急な学習曲線が観察された．参加者からは「マッチした移動方法を持つアバタは，キャラクターとのつながりをより感じさせた」「鏡でゴリラとしての自分を見ると，もっとゴリラのように振る舞いたくなった」といったフィードバックが得られている．ただし，Khanらの研究ではユーザは常に直立姿勢でVR体験を行っており，身体的姿勢の変化（例：四つん這い）については検討されていない．

Krekhovら（2019）~\cite{8848005}は，仮想の身体所有感の錯覚（Illusion of Virtual Body Ownership: IVBO）が非人間型アバタにも適用可能かを探求した．彼らは26名の参加者を対象に被験者内実験を実施し，人間の身体とは骨格，姿勢，形状が異なる3種類の動物アバタ（コウモリ，トラ，クモ）と人間アバタを比較した．動物の選定理由として，コウモリは人間と姿勢・骨格が類似しているが形状（プロポーション）が異なり，トラは骨格は類似しているが四足歩行という姿勢が異なり，クモは8本の脚を持つという骨格自体が大きく異なる．実験では，複数のボディマッピング手法が検証された．Full-body（FB）トラッキングではユーザの姿勢が動物の全身にマッピングされ，half-body（HB）トラッキングではユーザが直立姿勢を維持したまま下半身の動きのみを動物の全肢にマッピングする（例：人間の片脚がトラの2本の脚に対応）．また，一人称視点と三人称視点の比較も行われた．

実験の結果，IVBOは非人間型アバタにも適用可能であり，特にコウモリアバタはacceptance（受容）とcontrol（制御）の次元において人間アバタを有意に上回るスコアを獲得した．これは，人間に類似した直立姿勢と骨格を持つ動物がIVBOを誘発しやすいことを示唆している．重要な知見として，FBトラッキングとHBトラッキングの間でIVBOスコアに有意差は見られなかった．つまり，1:1の全身マッピングはIVBOの必要条件ではなく，HBアプローチでも同等のIVBO効果が得られることが示された．一方，FBモードでトラやクモを操作する場合，ユーザは床に這いつくばる必要があり，著しい疲労が報告された．HBモードはこの疲労を大幅に軽減しつつIVBOレベルを維持できるため，直立姿勢でない動物には有効な代替手段となる．また，一人称視点は三人称視点よりもIVBOにおいて優れていることが確認された．ただし，Krekhovらの研究は主にアバタ操作の静的または半静的な姿勢の一致に焦点を当てており，移動時の動作の運動学については深く調査されていない．

これら2つの研究は，それぞれ動作の整合性と身体的姿勢の重要性を独立に示しているが，両者の相互作用については検討されていない．本研究ではこれを拡張し，姿勢は単なる静的変数ではなく，移動中の動的な有効化要因であると考える．ユーザがアバタの方向と整合した姿勢をとることで，運動指令をアバタの動きに変換するために必要な認知的負荷が軽減され，整合的な動作パターンの効果が増幅される可能性がある~\cite{11192101, 10.3389/fpsyg.2017.01125}．

本研究の貢献は以下の3点である：

\begin{description}
\item[C1: 姿勢と動作整合性の相互作用効果の検証] Khanらの「動作整合性」フレームワークとKrekhovらの「姿勢」フレームワークを統合し，両者の交互作用効果を検証する．先行研究では，動作の整合性と身体的姿勢はそれぞれ独立した研究で行われてきた．そこで本研究では姿勢が動作整合性の効果を調整する可能性を探求する．具体的には，擬似四つん這い姿勢において動作整合性の効果が増幅されるという交互作用仮説を検証する．

\item[C2: ロコモーション整合性がプロテウス効果に与える影響の検証] 従来のプロテウス効果研究は主にアバタの視覚的外見に焦点を当ててきたが，本研究ではロコモーションの整合性がプロテウス効果を増強するかを検証する．具体的には，クマ的動作による移動が，参加者自身の身体能力知覚をクマの特性に近づけるかを測定し，動作の身体化が認知変容にもたらす影響を探求する．

\item[C3: ロコモーション文脈における動的身体化の探求] Krekhovらの研究は主に静的または半静的な姿勢の一致に焦点を当てており，移動時の動作の運動学については深く調査されていない．本研究では，VR空間内での能動的なロコモーション（移動）という動的文脈において，姿勢と動作マッピングが身体所有感および行為主体感に与える影響を検証する．これにより，非人間型アバタにおける身体化研究を，静的な姿勢マッチングから動的な運動体験へと拡張する．
\end{description}

\chapter{ユーザスタディ User Study}

\section{参加者 Participants}

本研究では，n名の参加者（男性n名，女性n名，平均年齢n歳，SD=n，範囲n-n歳）を対象に実験を実施した．参加者は全員，大学の学部生および大学院生である（実験時間：約60分）．

参加者には，感覚障害や運動障害の有無について尋ねた．3名の参加者が実験中に眼鏡を着用した．視覚障害や運動障害を報告した参加者はいなかった．また，VRおよびHMDの使用経験について7段階尺度（1: 全くない，2: 週に数回，3: 月に数回，4: 毎日）で尋ねた結果，x程度の経験レベルであった（M=n，SD=n）．

\section{研究デザインと仮説 Study Design and Hypotheses}

本研究では，被験者内計画（within-subjects design）を採用し，姿勢（Posture）とマッピング方法（Mapping Method）の2つの独立変数を設定した．各参加者は，これらの条件のすべての組み合わせをラテン方格法（Latin Square design）を用いてカウンターバランスした順序で体験した．実験条件は以下の4つである：

[image1: 4つの実験条件を示す図．C1からC4まで，アバタの姿勢とマッピング方法の組み合わせを視覚的に表現]

\begin{itemize}[noitemsep]
    \item C1（亜成体クマアバタ × クマ的動作）: 参加者は擬似四つん這い姿勢をとり，クマ的動作で移動する．視点の高さは亜成体クマの視点と一致．
    \item C2（亜成体クマアバタ × 人間的腕振り動作）: 参加者は擬似四つん這い姿勢をとり，人間的腕振り動作で移動する．視点の高さは亜成体クマの視点と一致．
    \item C3（成体クマアバタ × クマ的動作）: 参加者は立位姿勢をとり，クマ的動作で移動する．視点の高さは成体クマの視点と一致．
    \item C4（成体クマアバタ × 人間的腕振り動作）: 参加者は立位姿勢をとり，人間的腕振り動作で移動する．視点の高さは成体クマの視点と一致．
\end{itemize}

亜成体クマとは，成体クマに比べて小型であり，視点の高さも低い．生物学的にクマの亜成体とは，生後2〜5年目の個体を指す．成体クマは5歳以上の個体であり，体格が大きく視点の高さも高い~\cite{bartareau2011}．

ここで，擬似四つん這い姿勢は，参加者が両手と両膝を地面に接触させ，背中を水平に保つことで実現される．この姿勢は，クマの四足歩行の動作パターンを模倣することを目的としている．一方，立位姿勢では，参加者は自然な直立姿勢を維持する．
クマ的動作は，\textit{Ursus arctos}の生体力学データに基づいて設計されており，参加者は両手を前後に動かすことで前進する．一方，人間的腕振り動作では，参加者は自然な歩行時の腕振り動作を模倣する．
また，視点の高さは，亜成体クマ条件では地面から0.7メートル，成体クマ条件では1.6メートルに設定された．これにより，参加者は各姿勢においてクマの視点を体験できる．

本研究の主要な目的は，ユーザの物理的な姿勢（立位 vs 擬似四つん這い）と操作マッピング方法（クマ的 vs 人間的）が，身体所有感，行為主体感，疲労度，および全体的なユーザ体験に与える影響を比較検証することである．

以下の仮説を設定した：

\begin{description}
\item[H1] クマ的動作（高一致性マッピング）は，人間的腕振り動作（低一致性マッピング）よりも高い身体所有感（SoBO）と行為主体感（SoA）をもたらす．
\item[H2] 擬似四つん這い姿勢は，立位姿勢よりも高い身体所有感をもたらす．
\item[H3] 姿勢と動作マッピングの間には交互作用効果が存在する．具体的には，擬似四つん這い姿勢において，動作の整合性（クマ的 vs 人間的腕振り）が身体所有感と行為主体感に与える効果は，立位姿勢よりも大きくなる．
\end{description}

\section{手順 Procedure}

実験室に到着後，参加者には同意書を読んで署名してもらった．その後，実験前アンケートに回答し，人口統計情報および感覚・運動障害の有無を報告してもらった．

[image2: 実験環境の写真．参加者がHMDを装着している様子]

実験者は，クマ的動作と人間的腕振り動作の使用方法について説明した．参加者はすべての移動方法を練習し，現実の世界で最大3分間の時間が設けられた．これは，実験の本番前にアバタへの露出によるバイアスを制限するための設計である．

学習フェーズが完了すると，実験者は残りの手順について参加者に説明した．これは，HMDを再び装着し，3.2節で説明した4つの条件に対応する，開発されたプログラムの4つのバージョンを体験することで構成された．

各条件において，参加者は2分間VR空間内で過ごした．この間，参加者は十分に広いオープンワールドの草原の仮想環境で移動タスクを体験した．移動フェーズでは，参加者は前方視野角120度の範囲内で視線を向けることが求められ，上下方向への視線移動は許可された．シーン上に提示された目標ポイントに向かって前進することがタスクとして与えられたが，目標ポイントを超えることも，到達しないことも許容された．このタスクの主目的は，参加者がクマのように歩行できるかを評価することであった．

[image4: VR空間内のオープンワールド草原環境の様子．広大な草原に目標ポイントが提示されている]

2分間が経過した後，実験者は参加者にHMDを外すよう依頼し，アンケートに回答してもらった．このプロセスは，4つの条件すべてに対して繰り返された．各条件の完了後，参加者には2分間の休憩時間が与えられた．休憩が不十分であると感じた場合は，参加者に追加の休憩時間を申し出るよう促した．

4つの条件すべてが完了した後，参加者には実験全体を通じてのコメントを尋ね，実験を終了した．

\section{測定項目 Measures}

本研究では，アバタへの身体化，ユーザ体験，およびプロテウス効果を測定するために，複数の標準化された質問紙を使用した．

アバタへの身体化を測定するために，Peck \& Gonzalez-Franco（2021）によって検証・標準化されたAvatar Embodiment質問紙を使用した~\cite{10.3389/frvir.2020.575943}．この質問紙は，9つの実験から収集された443件以上の回答データに基づく探索的因子分析により，当初の25項目から16項目に精緻化されたもので，身体化感覚は相互に関連する4つのサブスケール(Appearance（外見），Response（応答性），Ownership（身体所有感），Multi-Sensory（多感覚統合）)で構成されることが示された．各サブスケールは高い信頼性を示し（Cronbach's $\alpha$ = 0.72--0.82），この質問紙は元の質問紙と比較してより広いスコア範囲を提供し，個人差の検出に優れることが検証されている．本研究では，この質問紙の16項目のうち，クマアバタの特性に適合する6項目を選択して使用した．各項目は7段階のリッカート尺度（1: 全くそう思わない，7: 非常に強くそう思う）で評価された．これらの項目から，身体所有感（SoBO）と行為主体感（SoA）のスコアを算出した．

タスク負荷を測定するために，NASA-TLXを使用した~\cite{HART1988139}．NASA-TLXは，知的要求，身体的要求，時間的切迫感，遂行成績，努力，フラストレーションの6つの次元から構成される．各次元は0から20の範囲で評価される．

ユーザ体験を測定するために，複数の標準化された尺度を採用した．Khanら（2025）~\cite{11192101}の研究では，アバタと移動方法の整合性が身体化だけでなく，楽しさ（enjoyment），満足度（satisfaction），学習のしやすさ（ease of learning）といったユーザ体験にも有意な影響を与えることが示されている．本研究でも同様に，姿勢と動作マッピングの整合性がユーザ体験に与える影響を検証するため，楽しさ（Enjoyment）と能力感（Competence）をIntrinsic Motivation Inventory（IMI）~\cite{Deci1985}から評価した．楽しさは，VR体験における内発的動機づけの中核的要素であり，身体化の質と関連することが示唆されている．能力感は，ユーザがアバタを効果的に操作できているという主観的評価を反映し，特に新規の動作マッピング（クマ的動作）の習得しやすさを評価する上で重要である．各項目は7段階のリッカート尺度（1: 全くそう思わない，7: 非常に強くそう思う）で評価された．

アバタの身体的特性に関する知覚を評価するために，クマの典型的な身体能力（速度，身体サイズ，重量，力強さ）に関する項目を作成した．本研究では，クマアバタへの身体化が，参加者自身の身体能力の知覚をクマの特性に近づけるかどうかを検証するため，これらの項目を設定した．速度は，ロコモーション体験において最も直接的に知覚される運動特性であり，移動速度の変化がアバタとしての移動能力の認識に影響を与える．身体サイズと重量は，クマの物理的存在感を表す基本的な属性であり，視点の高さや視覚的フィードバックを通じて知覚される身体スケールの変化を捉える．力強さは，四足歩行における前肢の推進力生成と関連し，特にクマ的動作における地面を押す動作が，力の行使感覚を強化すると予測される．これらの項目は，ロコモーションの身体化が単なる運動制御にとどまらず，アバタの身体的属性全体の内在化をもたらすかを評価するために選定された．特に，ロコモーションマッピングの一致性が高い条件では，アバタの身体的特徴がより強く内在化され，プロテウス効果が増強されると予測される．各項目は7段階のリッカート尺度（1: 全くそう思わない，7: 非常に強くそう思う）で評価された．

\chapter{システム詳細 System Details}

\section{アバタ動物の選定要件 Requirements for Avatar Animal Selection}

第3章で述べた実験を実施するためには，非人間型アバタとして以下の要件を満たす動物を選定する必要がある：

\begin{description}
\item[1: 姿勢条件に対応した視点高さの操作] 本実験では，擬似四つん這い姿勢と立位姿勢の2条件を比較する．各姿勢条件において，ユーザの物理的な目の高さとアバタの視点高さが一致している必要がある．したがって，同一種でありながら成長段階によって肩高が大きく異なり，かつその肩高が人間の擬似四つん這い時の目の高さと立位時の目の高さの両方に対応できる動物が求められる．
\item[2: 人間の手の動きと前肢の自然なマッピング] 本実験では，ユーザの手の動きをアバタの前肢にマッピングしてロコモーションを実現する．このマッピングが直感的かつ自然に感じられるためには，人間と類似した骨格構造や関節の動きを持つ動物が望ましい．
\end{description}

\section{クマ科動物の選定と前肢の生体力学 Bear Selection and Forelimb Biomechanics}

前節の要件を満たす動物として，本研究ではクマ科動物（ヒグマ，\textit{Ursus arctos}）を選定した．

ヒグマの肩高は成体で90--150 cmの範囲にあり~\cite{adw_ursus_arctos}，亜成体では約60 cmとなる~\cite{bartareau2011}．本研究では，この成長段階による体格差を利用し，亜成体条件では肩高を約60 cm（人間の擬似四つん這い時の目の高さに対応），成体条件では肩高を150 cm程度（人間の立位時の目の高さに対応）に設定した．

[image5: 亜成体クマと成体クマの肩高と視点の高さを示す図．人間の擬似四つん這い姿勢と立位姿勢との対応関係を視覚的に表現]

クマは蹠行性（plantigrade）歩行を行う大型哺乳類であり，人間と同様に足裏全体を地面に接地して歩行する~\cite{shine2016ursidae, polly2007}．趾行性や蹄行性の動物では接地姿勢が人間と大きく異なるため直感的なマッピングは困難であるが，蹠行性のクマでは人間の手の動きを前肢に自然にマッピングできる．

クマの四足歩行において，前肢は体重の54--60\%を支持し，全速度域において制動力は後肢より有意に大きい~\cite{10.1242/jeb.121806}．この力学的特性から，前肢のみの操作でも四足歩行の本質的な運動パターンを再現できる．本研究では前肢のみを視界内に提示する設計を採用した．

人間の手の動きをクマの前肢にマッピングする際，前腕部の回内・回外運動の可動性が重要となる．ヒグマの亜成体では前腕の回内・回外角度が約70--80度であり，最大回内位置が通常の接地姿勢とほぼ一致する~\cite{amaike2021}．このため，VRにおいて人間の手のひらを下向きに構えた姿勢が，クマの前肢の接地姿勢に直接対応する．

クマの前肢と人間の上肢は，肩関節，肘関節，手根関節という三つの主要な関節を共有しており，運動自由度において構造的類似性を持つ~\cite{davis1949, pang2020}．この類似性により，人間の手と腕の動きをクマの前肢にマッピングすることが解剖学的に妥当となる．

これらの生物学的特性により，ユーザは手のひらを下向きに向けた状態で，手を前方に伸ばし地面を押すように後方に引く動作を繰り返すことで，蹠行性の推進メカニズムに基づいたクマ的操作が可能になる．


\section{ロコモーションの実装 Locomotion Implementation}

人間的腕振り動作は，標準的な「その場ジョギング」ロジックに基づいていると言われている．システムはMeta Quest 3コントローラの垂直速度ベクトル（$V_y$）を監視する．コントローラの上下運動が閾値（$V_{threshold} = 0.5$ m/s）を超えると，前方への速度が適用される：

\begin{equation}
    v_{forward} = k_{swing} \cdot |V_y|
\end{equation}

ここで，$k_{swing}$は速度変換係数（$k_{swing} = 2.0$）である．このマッピングは，人間の二足歩行における腕振りを，クマの前肢の動きに直接マッピングする．ナビゲーションとしては機能的に有効だが，クマの生体力学とは一致せず，対照条件として機能する．

実験時の教示では，参加者に「自然に歩くときのように腕を前後に振ってください」と指示した．この動作は人間にとって極めて直感的であり，特別な練習を必要としない．ユーザは立位または座位のまま，通常の歩行リズムで腕を振ることで移動できる．この条件は，動作の直感性は高いが，クマの実際の前肢運動パターンとは乖離しているため，低一致性マッピングとして位置づけられる．

[image6: 人間的腕振り動作のマッピングを示す図．コントローラの垂直方向の動きと，アバタの前進速度の関係を視覚的に表現]

クマ的動作は，4.2節で述べた前肢の生体力学的特性に基づいて設計された．本研究の実装では，コントローラの前後方向の速度（$V_z$）と垂直位置（$P_y$）を追跡する．コントローラが胸の高さの閾値（$H_{chest} = 0.8$ m）より低い位置で後方へ移動（$V_z < -0.3$ m/s）した際，推進力が生成される：

\begin{equation}
    v_{power} = k_{power} \cdot |V_z| \cdot \left(1 - \frac{P_y}{H_{chest}}\right)
\end{equation}

ここで，$k_{power}$は変換係数（$k_{power} = 3.0$）であり，$\left(1 - \frac{P_y}{H_{chest}}\right)$は位置に応じた重み付け項である．手が低い位置にあるほど，より大きな推進力が生成される．

コントローラが胸の高さの閾値より高い位置で前方へ移動（$V_z > 0.2$ m/s）した際は，推進力は生成されず，次の推進動作の準備となる．

実験時の教示では，参加者に「姿勢を前方重心に，手を前に出してから後ろに引いてください．」と指示した．この教示は，4.2節で述べたクマの前肢における回内位置での接地と，蹠行性による推進メカニズムを，ユーザが直感的に再現できるよう設計されている．

[image7: クマ的動作のマッピングを示す図．コントローラの前後方向の動きと，アバタの前進速度の関係を視覚的に表現]

また，本システムではユーザの手と腕の動きのみを用いてクマの前肢を操作する．触覚刺激がなくても視覚情報と運動（固有受容感覚）の同期だけで身体所有感の錯覚が形成されることが示されており~\cite{sanchezvives2010virtual}，本研究ではユーザの手と腕の動きから前肢の運動を推定し，視覚フィードバックを通じてクマの前肢動作を表現する．

IKシステムにおいて，肘の横方向への開き（フレア）にペナルティを与えるポールベクトル制約を導入した．この制約は，人間の上肢とクマの前肢の運動学的差異を補正するために必要である．人間の肩関節は高い可動性を持ち，肘を横方向（冠状面方向）に開くことが容易であるが，クマの前肢は四足歩行における効率的な推進力生成のために，主に矢状面（身体を左右に分割する垂直面）内で動作する~\cite{10.1242/jeb.121806}．ユーザが自然な動作を行う際，肩関節の可動性により肘が横方向に開くことがあるが，これをそのままクマの前肢にマッピングすると，生物学的に不自然な動きとなり，身体化感覚を損なう可能性がある．

ポールベクトル制約は，肘の位置ベクトルから矢状面方向の成分を抽出し，横方向への逸脱を定量化する．具体的には，肘の位置ベクトル$\vec{v}_{elbow}$から，矢状面の法線ベクトル$\vec{n}_{sagittal}$への射影成分を差し引くことで，矢状面から外れた横方向成分$\vec{v}_{pole}$を計算する：

\begin{equation}
    \vec{v}_{pole} = \vec{v}_{elbow} - (\vec{v}_{elbow} \cdot \vec{n}_{sagittal}) \vec{n}_{sagittal}
\end{equation}

ここで，$\vec{v}_{elbow}$は肘の位置ベクトル，$\vec{n}_{sagittal}$は矢状面の法線ベクトル（通常，身体の左右方向を表す単位ベクトル）である．$\vec{v}_{pole}$の大きさ$|\vec{v}_{pole}|$は，肘が矢状面からどれだけ逸脱しているかを示す指標となる．IKソルバーでは，この逸脱量に基づいてペナルティ項を目的関数に追加し，肘が矢状面内に近づくように最適化する．これにより，ユーザの肘が物理的に横方向に開いている場合でも，アバタの前肢は生物学的に正確な軌道（矢状面内での動作）を維持し，クマらしい重量感のある動きが視覚的に提示される．この制約は，クマの前肢における肩関節と肘関節の協調運動パターン~\cite{10.1242/jeb.140681}を反映し，四足歩行における前肢の推進メカニズムと整合的な視覚フィードバックを提供する．

これらのアプローチにより，限られた入力（前肢のみ）から四足歩行全体を表現することが可能となった．視覚運動同期，IKによる運動補完，「クマの前脚を使って移動する」という認知的フレーミングの三者が相互作用することで，ユーザは「クマとして歩いている」という身体化感覚を獲得できる．

\clearpage



% \chapter{参考文献 References}

% \begin{thebibliography}{99}

% % === Introduction ===
% \bibitem{guy2023sense}
% M. Guy, J.-M. Normand, C. Jeunet-Kelway and G. Moreau, ``The sense of embodiment in Virtual Reality and its assessment methods,'' \textit{Frontiers in Virtual Reality}, vol. 4, 2023, doi: 10.3389/frvir.2023.1141683, ISSN: 2673-4192.

% \bibitem{gonzalezfranco2017model}
% M. Gonzalez-Franco and J. Lanier, ``Model of Illusions and Virtual Reality,'' \textit{Frontiers in Psychology}, vol. 8, article 1125, 2017, doi: 10.3389/fpsyg.2017.01125.

% \bibitem{kalckert2012moving}
% A. Kalckert and H. H. Ehrsson, ``Moving a Rubber Hand that Feels Like Your Own: A Dissociation of Ownership and Agency,'' \textit{Frontiers in Human Neuroscience}, vol. 6, article 40, 2012.

% \bibitem{sanchezvives2010virtual}
% M. V. Sanchez-Vives, B. Spanlang, A. Frisoli, M. Bergamasco and M. Slater, ``Virtual Hand Illusion Induced by Visuomotor Correlations,'' \textit{PLOS ONE}, vol. 5, no. 4, e10381, Apr. 2010, doi: 10.1371/journal.pone.0010381.

% \bibitem{slater1995taking}
% M. Slater, M. Usoh and A. Steed, ``Taking steps: the influence of a walking technique on presence in virtual reality,'' \textit{ACM Trans. Comput.-Hum. Interact.}, vol. 2, no. 3, Sept. 1995, doi: 10.1145/210079.210084.

% \bibitem{bowman2004user}
% D. A. Bowman, E. Kruijff, J. J. Laviola and I. Poupyrev, \textit{3D User Interfaces: Theory and Practice}, Addison Wesley, 2004.

% \bibitem{bhandari2024walking}
% E. Bozgeyikli, A. Raij, S. Katkoori and R. Dubey, ``Point \& Teleport Locomotion Technique for Virtual Reality,'' in \textit{Proceedings of the 2016 Annual Symposium on Computer-Human Interaction in Play (CHI PLAY '16)}, 2016.

% \bibitem{mccullough2015myo}
% M. McCullough, H. Xu, J. Michelson, M. Jackoski, W. Pease, W. Cobb, W. Kalescky, J. Ladd and B. Williams, ``Myo arm: swinging to explore a VE,'' in \textit{Proceedings of the ACM SIGGRAPH Symposium on Applied Perception (SAP '15)}, Association for Computing Machinery, New York, NY, USA, 2015, doi: 10.1145/2804408.2804416.

% \bibitem{sayyad2020walking}
% E. Sayyad et al., ``Walking and Teleportation in Wide-area Virtual Reality Experiences,'' in \textit{2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)}, 2020.

% \bibitem{lugrin2018avatar}
% J.-L. Lugrin, M. Landeck, M. E. Latoschik, A. Hotho, G. Seufert, and M. Wittmann, ``Any `Body' There? Avatar Visibility Effects in a Virtual Reality Game,'' in \textit{2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, Tuebingen/Reutlingen, Germany, 2018, doi: 10.1109/VR.2018.8446229.

% \bibitem{dewez2020studying}
% D. Dewez, R. Fribourg, F. Argelaguet, L. Hoyet, D. Mestre, M. Slater and A. L\'ecuyer, ``Influence of Locomotion Technique on Sense of Embodiment during Virtual Reality Walking,'' in \textit{Proceedings of the 2020 ACM Symposium on Spatial User Interaction (SUI '20)}, Article 8, 2020.

% \bibitem{ahn2016experiencing}
% S. J. Ahn, J. Bostick, E. Ogle, K. L. Nowak, K. T. McGillicuddy and J. N. Bailenson, ``Experiencing Nature: Embodying Animals in Immersive Virtual Environments Increases Inclusion of Nature in Self and Involvement with Nature,'' \textit{Journal of Computer-Mediated Communication}, vol. 21, no. 6, 2016, doi: 10.1111/jcc4.12173.

% \bibitem{spangenberger2022becoming}
% P. Spangenberger et al., ``Becoming a Tree: A Multi-Study Exploration of Virtual Embodiment as a Tool for Environmental Connectedness,'' in \textit{Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI '22)}, Article 303, 2022.

% \bibitem{gagnon2023waddle}
% C. Gagnon et al., ``Waddle Like a Penguin: Embodiment and Empathy in VR,'' in \textit{Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23)}, Article 234, 2023.

% \bibitem{lan2023nonhuman}
% Y. Lan et al., ``The Proteus Effect in Non-Human Avatar Embodiment,'' \textit{Computers in Human Behavior}, vol. 142, article 107658, 2023.

% \bibitem{ratan2024proteus}
% R. Ratan et al., ``The Proteus Effect: A Review and Meta-Analysis of Avatar Embodiment Effects,'' \textit{Psychological Bulletin}, vol. 150, no. 2, 2024.

% \bibitem{jiang2023handavatar}
% Y. Jiang, Z. Li, M. He, D. Lindlbauer and Y. Yan, ``HandAvatar: Embodying Non-Humanoid Virtual Avatars through Hands,'' in \textit{Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23)}, Association for Computing Machinery, New York, NY, USA, Article 309, 2023, doi: 10.1145/3544548.3581027.

% \bibitem{chen2012kinetre}
% J. Chen, S. Izadi and A. Fitzgibbon, ``KinÊtre: animating the world with the human body,'' in \textit{Proceedings of the 25th annual ACM symposium on User interface software and technology (UIST '12)}, Association for Computing Machinery, New York, NY, USA, 2012, doi: 10.1145/2380116.2380171.

% \bibitem{seol2013creature}
% Y. Seol, C. O'Sullivan and J. Lee, ``Creature features: online motion puppetry for non-human characters,'' in \textit{Proceedings of the 12th ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA '13)}, Association for Computing Machinery, New York, NY, USA, 2013, doi: 10.1145/2485895.2485903.

% \bibitem{khan2025avatar}
% O. Khan, H. Nam and K. Kim, ``Impact of Avatar-Locomotion Congruence on User Experience and Identification in Virtual Reality,'' in \textit{IEEE Transactions on Visualization and Computer Graphics}, vol. 31, no. 11, Nov. 2025, doi: 10.1109/TVCG.2025.3616836.

% \bibitem{krekhov2019animal}
% A. Krekhov, S. Cmentowski and J. Krüger, ``The Illusion of Animal Body Ownership and Its Potential for Virtual Reality Games,'' in \textit{2019 IEEE Conference on Games (CoG)}, London, UK, Aug. 2019, doi: 10.1109/CIG.2019.8848005.

% % === Related Work ===
% \bibitem{weijs2021development}
% M. L. Weijs et al., ``The Development of Sense of Embodiment in Virtual Reality,'' \textit{Psychological Science}, vol. 32, no. 5, 2021.

% \bibitem{suk2023influence}
% H. J. Suk et al., ``The Influence of Avatar Appearance Similarity on User Embodiment and Presence in VR,'' in \textit{Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23)}, Article 567, 2023.

% \bibitem{medeiros2018keep}
% D. Medeiros et al., ``Keep My Head on My Shoulders! Why Third-Person is Bad for Navigation in VR,'' in \textit{Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology (VRST '18)}, Article 16, 2018.

% \bibitem{hedlund2024rowing}
% M. Hedlund, C. Bogdan, G. Meixner and A. Matviienko, ``Rowing Beyond: Investigating Steering Methods for Rowing-based Locomotion in Virtual Environments,'' in \textit{Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24)}, Association for Computing Machinery, New York, NY, USA, Article 631, 2024, doi: 10.1145/3613904.3642192.

% \bibitem{tao2023embodying}
% Y. Tao, C. Y. Wang, A. D. Wilson, E. Ofek and M. Gonzalez-Franco, ``Embodying Physics-Aware Avatars in Virtual Reality,'' in \textit{Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23)}, Association for Computing Machinery, New York, NY, USA, Article 254, 2023, doi: 10.1145/3544548.3580979.

% \bibitem{ogawa2020feel}
% N. Ogawa et al., ``Feel Like You Own the Virtual Body: Realistic Full-Body Ownership Illusion and Its Effect on Walking-Through-Walls,'' in \textit{2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 2020.

% \bibitem{krekhov2019beyond}
% A. Krekhov, S. Cmentowski, K. Emmerich and J. Krüger, ``Beyond Human: Animals as an Escape from Stereotype Avatars in Virtual Reality Games,'' in \textit{Proceedings of the Annual Symposium on Computer-Human Interaction in Play (CHI PLAY '19)}, Association for Computing Machinery, New York, NY, USA, Oct. 2019, doi: 10.1145/3311350.3347172.

% \bibitem{mal2023avatar}
% D. Mal et al., ``Avatar-Environment Congruence and Its Effect on Plausibility and Proteus Effect,'' in \textit{2023 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 2023.

% % === User Study ===
% \bibitem{peck2021embodiment}
% T. C. Peck and M. Gonzalez-Franco, ``Avatar Embodiment. A Standardized Questionnaire,'' \textit{Frontiers in Virtual Reality}, vol. 1, article 575943, Feb. 2021, doi: 10.3389/frvir.2020.575943.

% \bibitem{hart1988nasa}
% S. G. Hart and L. E. Staveland, ``Development of NASA-TLX (Task Load Index): Results of empirical and theoretical research,'' in P. A. Hancock and N. Meshkati (Eds.), \textit{Human Mental Workload}, North-Holland, 1988.

% \bibitem{choi2010imi}
% J. Choi, T. Mogami and A. Medalia, ``Intrinsic Motivation Inventory: An Adapted Measure for Schizophrenia Research,'' \textit{Schizophrenia Bulletin}, vol. 36, no. 5, Sept. 2010, doi: 10.1093/schbul/sbp030.

% % === System Details ===
% \bibitem{shine2016plantigrade}
% C. L. Shine, ``Ursidae locomotion: right down to the `bear bones','' Ph.D. dissertation, University of Idaho, 2016.

% \bibitem{shine2015grizzly}
% C. L. Shine, S. Penberthy, C. T. Robbins, O. L. Nelson and C. P. McGowan, ``Grizzly bear (Ursus arctos horribilis) locomotion: gaits and ground reaction forces,'' \textit{Journal of Experimental Biology}, vol. 218, no. 19, 2015, doi: 10.1242/jeb.121806.

% \bibitem{amaike2021forearm}
% H. Amaike, M. Sasaki, N. Tsuzuki, M. Kayano, M. Oishi, K. Yamada, H. Endo, T. Anezaki, N. Matsumoto, R. Nakashita, M. Kuroe, H. Taru, G. Bando, Y. Iketani, R. Nakamura, N. Sato, D. Fukui and N. Kitamura, ``Mobility of the forearm skeleton in the Asiatic black (Ursus thibetanus), brown (U. arctos) and polar (U. maritimus) bears,'' \textit{Journal of Veterinary Medical Science}, vol. 83, no. 9, 2021, doi: 10.1292/jvms.21-0216.

% \bibitem{adw2025bear}
% Animal Diversity Web, ``Ursus arctos (brown bear),'' University of Michigan Museum of Zoology, https://animaldiversity.org/accounts/Ursus\_arctos/, accessed Dec. 10, 2025.

% \bibitem{bartareau2011growth}
% T. M. Bartareau, H. D. Cluff and N. C. Larter, ``Body length and mass growth of the brown bear (Ursus arctos) in northern Canada: model selection based on information theory and ontogeny of sexual size dimorphism,'' \textit{Canadian Journal of Zoology}, vol. 89, no. 12, 2011, doi: 10.1139/z11-088.

% \bibitem{polly2007limbs}
% P. D. Polly, ``Limbs in mammalian evolution,'' in B. K. Hall (Ed.), \textit{Fins into Limbs: Evolution, Development, and Transformation}, University of Chicago Press, 2007.

% \bibitem{pang2020limbs}
% Pang, Z., Wang, T., Wang, Z., Yu, J., Sun, Z., \& Liu, S. (2020). Design and Analysis of a Wearable Upper Limb Rehabilitation Robot with Characteristics of Tension Mechanism. Applied Sciences, 10(6), 2101. https://doi.org/10.3390/app10062101

% \bibitem{davis1949shoulder}
% Davis, D. D. (1949). The shoulder architecture of bears and other carnivores. Fieldiana: Zoology, 31(34)

% \bibitem{shine2017grizzly}
% Shine, C. L., Robbins, C. T., Nelson, O. L., \& McGowan, C. P. (2017). Grizzly bear (Ursus arctos horribilis) locomotion: forelimb joint mechanics across speed in the sagittal and frontal planes. Journal of Experimental Biology, 220(7)

% \end{thebibliography}

