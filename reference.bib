@ARTICLE{10.3389/frvir.2023.1141683,

AUTHOR={Guy, Martin  and Normand, Jean-Marie  and Jeunet-Kelway, Camille  and Moreau, Guillaume },

TITLE={The sense of embodiment in Virtual Reality and its assessment methods},

JOURNAL={Frontiers in Virtual Reality},

VOLUME={Volume 4 - 2023},

YEAR={2023},

URL={https://www.frontiersin.org/journals/virtual-reality/articles/10.3389/frvir.2023.1141683},

DOI={10.3389/frvir.2023.1141683},

ISSN={2673-4192},

ABSTRACT={The sense of embodiment refers to the sensations with being inside, having and controlling a body. In virtual reality, it is possible to substitute a person's body with a virtual one, referred to as an avatar. Modulations of the sense of embodiment through modifications of this avatar have perceptual and behavioural consequences on users that can influence the way users interact with the virtual environment. Therefore, it is essential to define metrics that enable a reliable assessment of the sense of embodiment in virtual reality to better understand its dimensions, the way they interact, and the influence that they have on the quality of interaction in the virtual environment. In this review, we first introduce the current knowledge on the sense of embodiment, its dimensions (senses of agency, body ownership, and self-location), and how they relate the ones with the others. Then, we dive into the different methods currently used to assess the sense of embodiment, ranging from questionnaires to neurophysiological measures. We provide a critical analysis of the existing metrics, discussing their advantages and drawbacks in the context of virtual reality. Notably, we argue that real-time measures of embodiment, that are also specific and do not require double-tasking are the most relevant in the context of virtual reality. Electroencephalography seems a good candidate for the future if its drawbacks (such as its sensitivity to movement and practicality) are improved. While the perfect metric has yet to be identified if it exists, this work provides clues on which metric to choose depending on the context, which should hopefully contribute to better assessing and understanding the sense of embodiment in virtual reality.}}

@ARTICLE{10.3389/fpsyg.2017.01125,

AUTHOR={Gonzalez-Franco, Mar  and Lanier, Jaron },

TITLE={Model of Illusions and Virtual Reality},

JOURNAL={Frontiers in Psychology},

VOLUME={Volume 8 - 2017},

YEAR={2017},

URL={https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2017.01125},

DOI={10.3389/fpsyg.2017.01125},

ISSN={1664-1078},

ABSTRACT={In Virtual Reality (VR) it is possible to induce illusions in which users report and behave as if they have entered into altered situations and identities. The effect can be robust enough for participants to respond “realistically”, meaning behaviors are altered as if subjects had been exposed to the scenarios in reality. The circumstances in which such VR illusions take place were first introduced in the 80’s. Since then, rigorous empirical evidence has explored a wide set of illusory experiences in VR. Here we compile this research and propose a neuroscientific model explaining the underlying perceptual and cognitive mechanisms that enable illusions in VR. Furthermore, we describe the minimum instrumentation requirements to support illusory experiences in VR, and discuss the importance and shortcomings of the generic model.}}

@ARTICLE{10.3389/fnhum.2012.00040,

AUTHOR={Kalckert, Andreas  and Ehrsson, H H.},

TITLE={Moving a Rubber Hand that Feels Like Your Own: A Dissociation of Ownership and Agency},

JOURNAL={Frontiers in Human Neuroscience},

VOLUME={Volume 6 - 2012},

YEAR={2012},

URL={https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2012.00040},

DOI={10.3389/fnhum.2012.00040},

ISSN={1662-5161},

ABSTRACT={During voluntary hand movement, we sense that we generate the movement and that the hand is a part of our body. These feelings of control over bodily actions, or the sense of agency, and the ownership of body parts are two fundamental aspects of the way we consciously experience our bodies. However, little is known about how these processes are functionally linked. Here, we introduce a version of the rubber hand illusion in which participants control the movements of the index finger of a model hand, which is in full view, by moving their own right index finger. We demonstrated that voluntary finger movements elicit a robust illusion of owning the rubber hand and that the senses of ownership and agency over the model hand can be dissociated. We systematically varied the relative timing of the finger movements (synchronous vs. asynchronous), the mode of movement (active vs. passive), and the position of the model hand (anatomically congruent vs. incongruent positions). Importantly, asynchrony eliminated both ownership and agency, passive movements abolished the sense of agency but left ownership intact, and incongruent positioning of the model hand diminished ownership but did not eliminate agency. These findings provide evidence for a double dissociation of ownership and agency, suggesting that they represent distinct cognitive processes. Interestingly, we also noted that the sense of agency was stronger when the hand was perceived to be a part of the body, and only in this condition did we observe a significant correlation between the subjects’ ratings of agency and ownership. We discuss this in the context of possible differences between agency over owned body parts and agency over actions that involve interactions with external objects. In summary, the results obtained in this study using a simple moving rubber hand illusion paradigm extend previous findings on the experience of ownership and agency and shed new light on their relationship.}}

@article{10.1371/journal.pone.0010381,
  title={Virtual Hand Illusion Induced by Visuomotor Correlations},
  author={Sanchez-Vives, Maria V. and Spanlang, Bernhard and Frisoli, Antonio and Bergamasco, Massimo and Slater, Mel},
  journal={PLoS ONE},
  volume={5},
  number={4},
  pages={e10381},
  year={2010},
  publisher={Public Library of Science},
  doi={10.1371/journal.pone.0010381}
}

@article{10.1145/210079.210084,
author = {Slater, Mel and Usoh, Martin and Steed, Anthony},
title = {Taking steps: the influence of a walking technique on presence in virtual reality},
year = {1995},
issue_date = {Sept. 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
issn = {1073-0516},
url = {https://doi.org/10.1145/210079.210084},
doi = {10.1145/210079.210084},
abstract = {This article presents an interactive technique for moving through an immersive virtual environment (or “virtual reality”). The technique is suitable for applications where locomotion is restricted to ground level. The technique is derived from the idea that presence in virtual environments may be enhanced the stronger the match between proprioceptive information from human body movements and sensory feedback from the computer-generated displays. The technique is an attempt to simulate body movements associated with walking. The participant “walks in place” to move through the virtual environment across distances greater than the physical limitations imposed by the electromagnetic tracking devices. A neural network is used to analyze the stream of coordinates  from the head-mounted display, to determine whether or not the participant is walking on the spot. Whenever it determines the walking behavior, the participant is moved through virtual space in the direction of his or her gaze. We discuss two experimental studies to assess the impact on presence of this method in comparison to the usual hand-pointing method of navigation in virtual reality. The studies suggest that subjective rating of presence is enhanced by the walking method provided that participants associate subjectively with the virtual body provided in the environment. An application of the technique to climbing steps and ladders is also presented.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = sep,
pages = {201–219},
numpages = {19},
keywords = {virtual reality, virtual environments, presence, neural networks, navigation, locomotion, immersion}
}

@inbook{inbook,
author = {Bowman, Doug and Kruijff, Ernst and LaViola, Ivan},
year = {2004},
month = {08},
pages = {-512},
title = {3D User Interfaces: Theory and Practice},
isbn = {0201758679}
}

@inproceedings{10.1145/2967934.2968105,
author = {Bozgeyikli, Evren and Raij, Andrew and Katkoori, Srinivas and Dubey, Rajiv},
title = {Point \& Teleport Locomotion Technique for Virtual Reality},
year = {2016},
isbn = {9781450344562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2967934.2968105},
doi = {10.1145/2967934.2968105},
abstract = {With the increasing popularity of virtual reality (VR) and new devices getting available with relatively lower costs, more and more video games have been developed recently. Most of these games use first person interaction techniques since it is more natural for Head Mounted Displays (HMDs). One of the most widely used interaction technique in VR video games is locomotion that is used to move user's viewpoint in virtual environments. Locomotion is an important component of video games since it can have a strong influence on user experience. In this study, a new locomotion technique we called "Point \& Teleport" is described and compared with two commonly used VR locomotion techniques of walk-in-place and joystick. In this technique, users simply point where they want to be in virtual world and they are teleported to that position. As a major advantage, it is not expected to introduce motion sickness since it does not involve any visible translational motion. In this study, two VR experiments were designed and performed to analyze the Point \& Teleport technique. In the first experiment, Point \& Teleport was compared with walk-in-place and joystick locomotion techniques. In the second experiment, a direction component was added to the Point \& Teleport technique so that the users could specify their desired orientation as well. 16 users took part in both experiments. Results indicated that Point \& Teleport is a fun and user friendly locomotion method whereas the additional direction component degraded the user experience.},
booktitle = {Proceedings of the 2016 Annual Symposium on Computer-Human Interaction in Play},
pages = {205–216},
numpages = {12},
keywords = {virtual reality, teleportation, locomotion},
location = {Austin, Texas, USA},
series = {CHI PLAY '16}
}

@inproceedings{10.1145/2804408.2804416,
author = {McCullough, Morgan and Xu, Hong and Michelson, Joel and Jackoski, Matthew and Pease, Wyatt and Cobb, William and Kalescky, William and Ladd, Joshua and Williams, Betsy},
title = {Myo arm: swinging to explore a VE},
year = {2015},
isbn = {9781450338127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2804408.2804416},
doi = {10.1145/2804408.2804416},
abstract = {In this paper, we use an inexpensive wearable device called the Myo armband (199 USD) to implement a simple arm swinging algorithm that allows a user to freely explore an HMD-based virtual environment. Using a spatial orientation task we directly compared our Myo arm--swinging method to joystick locomotion and physical walking. We find that our arm swinging method outperforms the simple joystick and that spatial orientation is comparable to physically walking on foot. Our arm--swinging method is inexpensive compared to tracking systems that permit foot exploration, does not suffer from space constraints, and requires less physical energy than walking on foot.},
booktitle = {Proceedings of the ACM SIGGRAPH Symposium on Applied Perception},
pages = {107–113},
numpages = {7},
keywords = {head-mounted display, locomotion, spatial updating, virtual environment},
location = {T\"{u}bingen, Germany},
series = {SAP '15}
}

@inproceedings{10.1109/ISMAR50242.2020.00088,
author = {Sayyad, Ehsan and Sra, Misha and Hollerer, Tobias},
year = {2020},
month = {11},
pages = {608-617},
title = {Walking and Teleportation in Wide-area Virtual Reality Experiences},
doi = {10.1109/ISMAR50242.2020.00088}
}

@INPROCEEDINGS{8446229,
  author={Lugrin, Jean-Luc and Ertl, Maximilian and Krop, Philipp and Klüpfel, Richard and Stierstorfer, Sebastian and Weisz, Bianka and Rück, Maximilian and Schmitt, Johann and Schmidt, Nina and Latoschik, Marc Erich},
  booktitle={2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  title={Any “Body” There? Avatar Visibility Effects in a Virtual Reality Game},
  year={2018},
  volume={},
  number={},
  pages={17-24},
  keywords={Avatars;Games;Visualization;Virtual environments;Torso;Mirrors;Human-centered computing-Human computer interaction (HCl)-Interaction paradigms-Virtual reality},
  doi={10.1109/VR.2018.8446229}}

@inproceedings{10.1109/ISMAR50242.2020.00070,
author = {Dewez, Diane and Hoyet, Ludovic and Lécuyer, Anatole and Argelaguet, Ferran},
year = {2020},
month = {11},
pages = {452-461},
title = {Studying the Inter-Relation Between Locomotion Techniques and Embodiment in Virtual Reality},
doi = {10.1109/ISMAR50242.2020.00070}
}

@article{10.1111/jcc4.12173,
    author = {Ahn, Sun Joo (Grace) and Bostick, Joshua and Ogle, Elise and Nowak, Kristine L. and McGillicuddy, Kara T. and Bailenson, Jeremy N.},
    title = {Experiencing Nature: Embodying Animals in Immersive Virtual Environments Increases Inclusion of Nature in Self and Involvement with Nature},
    journal = {Journal of Computer-Mediated Communication},
    volume = {21},
    number = {6},
    pages = {399-419},
    year = {2016},
    month = {09},
    abstract = {Immersive virtual environments (IVEs) produce simulations that mimic unmediated sensory experiences. 3 experiments (N = 228) tested how different modalities increase environmental involvement by allowing users to inhabit the body of animals in IVEs or watch the experience on video. Embodying sensory-rich experiences of animals in IVEs led to greater feeling of embodiment, perception of being present in the virtual world, and interconnection between the self and nature compared to video. Heightened interconnection with nature elicited greater perceptions of imminence of the environmental risk and involvement with nature, which persisted for 1 week. Although the effect sizes were small to moderate, findings suggest that embodied experiences in IVEs may be an effective tool to promote involvement with environmental issues.},
    issn = {1083-6101},
    doi = {10.1111/jcc4.12173},
    url = {https://doi.org/10.1111/jcc4.12173},
    eprint = {https://academic.oup.com/jcmc/article-pdf/21/6/399/19946792/jjcmcom0399.pdf},
}

@article{10.1038/s41598-022-05184-0,
  title={Becoming nature: effects of embodying a tree in immersive virtual reality on nature relatedness},
  author={Spangenberger, Pia and Geiger, Sonja Maria and Freytag, Sarah-Christin},
  journal={Scientific Reports},
  volume={12},
  number={1},
  pages={1311},
  year={2022},
  publisher={Nature Publishing Group},
  doi={10.1038/s41598-022-05184-0},
  url={https://doi.org/10.1038/s41598-022-05184-0}
}

@inproceedings{10.1145/3611659.3617211,
author = {Ponto, Kevin and Tredinnick, Ross and Verbeke, Monae and Kopp, Kaldan and Swanson, Luke and Gagnon, David},
title = {Waddle: using virtual penguin embodiment as a vehicle for empathy and informal learning},
year = {2023},
isbn = {9798400703287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611659.3617211},
doi = {10.1145/3611659.3617211},
abstract = {This paper presents, Waddle, a virtual experience to promote informal learning by embodying the user as an Ad\'{e}lie Penguin to partake in a narrative-based virtual reality application that shares the story of the lives of these unique animals. We test the effects of this experience on informal learning and empathy, an important component for fostering social engagement with ecology. The research demonstrates that the developed experience is able to support informal learning, virtual embodiment, and is able to create a positive change in empathy.},
booktitle = {Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology},
articleno = {90},
numpages = {2},
keywords = {Empathy, Informal Learning, Virtual Embodiment},
location = {Christchurch, New Zealand},
series = {VRST '23}
}

@article{LAN2023100020,
title = {Can non-humanlike avatars induce the Proteus effect? The roles of avatar identification and embodiment in influencing social participation},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {1},
number = {2},
pages = {100020},
year = {2023},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2023.100020},
url = {https://www.sciencedirect.com/science/article/pii/S2949882123000208},
author = {Xinmiao Lan and Zeph M.C. {van Berlo}},
keywords = {Proteus effect, Non-humanlike avatars, Avatar identification, Embodiment, Virtual reality (VR)},
abstract = {In virtual environments, people tend to behave in line with the virtual avatars they embody. For example, when an individual embodies an attractive and physically fit avatar, they might show an increase in self-esteem. This phenomenon is called the Proteus effect. While prior research shows support for this effect with humanlike avatars, it is unclear whether non-humanlike avatars can also induce it. In this study, we examine the Proteus effect in the context of non-humanlike avatars and test whether the level of attractiveness of a non-humanlike avatar affects social participation. Two underlying mechanisms of the Proteus effect are considered: the mediating role of avatar identification and the moderating role of level of embodiment. To test our hypotheses, a 2 x 2 between-subjects lab experiment (N = 134) was conducted. Participants were randomly assigned to one of two non-humanlike avatars differing in level of attractiveness (attractive vs. unattractive) and one of two levels of embodiment (head-mounted display VR vs. desktop). The results showed that participants embodying the attractive non-humanlike avatar perceived higher levels of avatar identification via self-similarity, which increased social participation. Also, this study found that level of embodiment did not moderate the effect of attractiveness of the non-humanlike avatar on social participation.}
}
@article{10.1016/j.chbah.2023.100020,
author = {Lan, Xinmiao and van Berlo, Zeph},
year = {2023},
month = {10},
pages = {},
title = {Can non-humanlike avatars induce the Proteus effect? The roles of avatar identification and embodiment in influencing social participation},
volume = {1},
journal = {Computers in Human Behavior Artificial Humans},
doi = {10.1016/j.chbah.2023.100020}
}

@inproceedings{10.1145/3544548.3581027,
author = {Jiang, Yu and Li, Zhipeng and He, Mufei and Lindlbauer, David and Yan, Yukang},
title = {HandAvatar: Embodying Non-Humanoid Virtual Avatars through Hands},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581027},
doi = {10.1145/3544548.3581027},
abstract = {We propose HandAvatar to enable users to embody non-humanoid avatars using their hands. HandAvatar leverages the high dexterity and coordination of users’ hands to control virtual avatars, enabled through our novel approach for automatically-generated joint-to-joint mappings. We contribute an observation study to understand users’ preferences on hand-to-avatar mappings on eight avatars. Leveraging insights from the study, we present an automated approach that generates mappings between users’ hands and arbitrary virtual avatars by jointly optimizing control precision, structural similarity, and comfort. We evaluated HandAvatar on static posing, dynamic animation, and creative exploration tasks. Results indicate that HandAvatar enables more precise control, requires less physical effort, and brings comparable embodiment compared to a state-of-the-art body-to-avatar control method. We demonstrate HandAvatar’s potential with applications including non-humanoid avatar based social interaction in VR, 3D animation composition, and VR scene design with physical proxies. We believe that HandAvatar unlocks new interaction opportunities, especially for usage in Virtual Reality, by letting users become the avatar in applications including virtual social interaction, animation, gaming, or education.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {309},
numpages = {17},
keywords = {Mixed Reality, embodiment, gestural interaction, virtual avatar},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/2380116.2380171,
author = {Chen, Jiawen and Izadi, Shahram and Fitzgibbon, Andrew},
title = {Kin\^{E}tre: animating the world with the human body},
year = {2012},
isbn = {9781450315807},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2380116.2380171},
doi = {10.1145/2380116.2380171},
abstract = {Kin\^{E}tre allows novice users to scan arbitrary physical objects and bring them to life in seconds. The fully interactive system allows diverse static meshes to be animated using the entire human body. Traditionally, the process of mesh animation is laborious and requires domain expertise, with rigging specified manually by an artist when designing the character. Kin\^{E}tre makes creating animations a more playful activity, conducted by novice users interactively "at runtime". This paper describes the Kin\^{E}tre system in full, highlighting key technical contributions and demonstrating many examples of users animating meshes of varying shapes and sizes. These include non-humanoid meshes and incomplete surfaces produced by 3D scanning - two challenging scenarios for existing mesh animation systems. Rather than targeting professional CG animators, Kin\^{E}tre is intended to bring mesh animation to a new audience of novice users. We demonstrate potential uses of our system for interactive storytelling and new forms of physical gaming.},
booktitle = {Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology},
pages = {435–444},
numpages = {10},
keywords = {3d interfaces, depth cameras, mesh animation, real-time},
location = {Cambridge, Massachusetts, USA},
series = {UIST '12}
}

@inproceedings{10.1145/2485895.2485903,
author = {Seol, Yeongho and O'Sullivan, Carol and Lee, Jehee},
title = {Creature features: online motion puppetry for non-human characters},
year = {2013},
isbn = {9781450321327},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2485895.2485903},
doi = {10.1145/2485895.2485903},
abstract = {We present a novel real-time motion puppetry system that drives the motion of non-human characters using human motion input. We aim to control a variety of creatures whose body structures and motion patterns can differ greatly from a human's. A combination of direct feature mapping and motion coupling enables the generation of natural creature motion, along with intuitive and expressive control for puppetry. First, in the design phase, direct feature mappings and motion classification can be efficiently and intuitively computed given crude motion mimicking as input. Later, during the puppetry phase, the user's body motions are used to control the target character in real-time, using the combination of feature mappings generated from the design phase. We demonstrate the effectiveness of our approach with several examples of natural puppetry, where a variety of non-human creatures are controlled in real-time using human motion input from a commodity motion sensing device.},
booktitle = {Proceedings of the 12th ACM SIGGRAPH/Eurographics Symposium on Computer Animation},
pages = {213–221},
numpages = {9},
keywords = {real-time, puppetry, non-human character, motion, animation},
location = {Anaheim, California},
series = {SCA '13}
}

@ARTICLE{11192101,
  author={Khan, Omar and Nam, Hyeongil and Kim, Kangsoo},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  title={Impact of Avatar-Locomotion Congruence on User Experience and Identification in Virtual Reality},
  year={2025},
  volume={31},
  number={11},
  pages={9878-9888},
  keywords={Avatars;User experience;Virtual environments;Navigation;Games;Legged locomotion;Visualization;Teleportation;Training;Data mining;Virtual reality;avatars;appearance;locomotion;avatar identification;user experience;gamification},
  doi={10.1109/TVCG.2025.3616836}}

@INPROCEEDINGS{8848005,
  author={Krekhov, Andrey and Cmentowski, Sebastian and Krüger, Jens},
  booktitle={2019 IEEE Conference on Games (CoG)},
  title={The Illusion of Animal Body Ownership and Its Potential for Virtual Reality Games},
  year={2019},
  volume={},
  number={},
  pages={1-8},
  keywords={Animals;Avatars;Games;Humanoid robots;Skeleton;Visualization;Data analysis;virtual reality;animal avatars;embodiment},
  doi={10.1109/CIG.2019.8848005}}

@article{weijs2023movement,
  title={Movement control and avatar appearance modulate the sense of body ownership and agency in children and adults},
  author={Weijs, Marieke Lieve and Macartney, Elle and Daum, Moritz M and Lenggenhager, Bigna},
  journal={Journal of Experimental Child Psychology},
  volume={226},
  pages={105558},
  year={2023},
  publisher={Elsevier},
  doi={10.1016/j.jecp.2022.105558}
}




@article{10.1177/0956797612462902,
author = {Dorothy Cowie and Tamar R. Makin and Andrew J. Bremner},
title ={Children’s Responses to the Rubber-Hand Illusion Reveal Dissociable Pathways in Body Representation},

journal = {Psychological Science},
volume = {24},
number = {5},
pages = {762-769},
year = {2013},
doi = {10.1177/0956797612462902},
    note ={PMID: 23538915},

URL = {

        https://doi.org/10.1177/0956797612462902



},
eprint = {

        https://doi.org/10.1177/0956797612462902



}
,
    abstract = { The bodily self is constructed from multisensory information. However, little is known of the relation between multisensory development and the emerging sense of self. We investigated this question by measuring the strength of the rubber-hand illusion in young children (4 to 9 years old) and adults. Intermanual pointing showed that children were as sensitive as adults to visual-tactile synchrony cues for hand position, which indicates that a visual-tactile pathway to the bodily self matures by at least 4 years of age. However, regardless of synchrony cues, children’s perceived hand position was closer to the rubber hand than adults’ perceived hand position was. This indicates a second, later-maturing process based on visual-proprioceptive information. Furthermore, explicit feelings of embodiment were related only to the visual-tactile process. These findings demonstrate two dissociable processes underlying body representation in early life, and they call into question current models of body representation and ownership in adulthood. }
}
@inproceedings{10.1145/3281505.3281511,
author = {Medeiros, Daniel and dos Anjos, Rafael K. and Mendes, Daniel and Pereira, Jo\~{a}o Madeiras and Raposo, Alberto and Jorge, Joaquim},
title = {Keep my head on my shoulders! why third-person is bad for navigation in VR},
year = {2018},
isbn = {9781450360869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3281505.3281511},
doi = {10.1145/3281505.3281511},
abstract = {Head-Mounted Displays are useful to place users in virtual reality (VR). They do this by totally occluding the physical world, including users' bodies. This can make self-awareness problematic. Indeed, researchers have shown that users' feeling of presence and spatial awareness are highly influenced by their virtual representations, and that self-embodied representations (avatars) of their anatomy can make the experience more engaging. On the other hand, recent user studies show a penchant towards a third-person view of one's own body to seemingly improve spatial awareness. However, due to its unnaturality, we argue that a third-person perspective is not as effective or convenient as a first-person view for task execution in VR. In this paper, we investigate, through a user evaluation, how these perspectives affect task performance and embodiment, focusing on navigation tasks, namely walking while avoiding obstacles. For each perspective, we also compare three different levels of realism for users' representation, specifically a stylized abstract avatar, a mesh-based generic human, and a real-time point-cloud rendering of the users' own body. Our results show that only when a third-person perspective is coupled with a realistic representation, a similar sense of embodiment and spatial awareness is felt. In all other cases, a first-person perspective is still better suited for navigation tasks, regardless of representation.},
booktitle = {Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology},
articleno = {16},
numpages = {10},
keywords = {augmented reality, avatar, embodiment, full-body tracking, travel, virtual reality},
location = {Tokyo, Japan},
series = {VRST '18}
}

@inproceedings{10.1145/3613904.3642192,
author = {Hedlund, Martin and Bogdan, Cristian and Meixner, Gerrit and Matviienko, Andrii},
title = {Rowing Beyond: Investigating Steering Methods for Rowing-based Locomotion in Virtual Environments},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642192},
doi = {10.1145/3613904.3642192},
abstract = {Rowing has great potential in Virtual Reality (VR) exergames as it requires physical effort and uses physical motion to map the locomotion in a virtual space. However, rowing in VR is currently restricted to locomotion along one axis, leaving 2D and 3D locomotion out of the scope. To facilitate rowing-based locomotion, we implemented three steering techniques based on head, hands, and feet movements for 2D and 3D VR environments. To investigate these methods, we conducted a controlled experiment (N = 24) to assess the user performance, experience and VR sickness. We found that head steering leads to fast and precise steering in 2D and 3D, and hand steering is the most realistic. Feet steering had the largest performance difference between 2D and 3D but comparable precision to hands in 2D. Lastly, head steering is the least mentally demanding, and all methods had comparable VR sickness.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {631},
numpages = {17},
keywords = {exergame, locomotion, rowing, steering, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3544548.3580979,
author = {Tao, Yujie and Wang, Cheng Yao and Wilson, Andrew D and Ofek, Eyal and Gonzalez-Franco, Mar},
title = {Embodying Physics-Aware Avatars in Virtual Reality},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580979},
doi = {10.1145/3544548.3580979},
abstract = {Embodiment toward an avatar in virtual reality (VR) is generally stronger when there is a high degree of alignment between the user’s and self-avatar’s motion. However, one-to-one mapping between the two is not always ideal when user interacts with the virtual environment. On these occasions, the user input often leads to unnatural behavior without physical realism (e.g., objects penetrating virtual body, body unmoved by hitting stimuli). We investigate how adding physics correction to self-avatar motion impacts embodiment. Physics-aware self-avatar preserves the physical meaning of the movement but introduces discrepancies between the user’s and self-avatar’s motion, whose contingency is a determining factor for embodiment. To understand its impact, we conducted an in-lab study (n = 20) where participants interacted with obstacles on their upper bodies in VR with and without physics correction. Our results showed that, rather than compromising embodiment level, physics-responsive self-avatar improved embodiment compared to no-physics condition in both active and passive interactions.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {254},
numpages = {15},
keywords = {Embodiment, Physics Avatars, Virtual Reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3313831.3376562,
author = {Ogawa, Nami and Narumi, Takuji and Kuzuoka, Hideaki and Hirose, Michitaka},
title = {Do You Feel Like Passing Through Walls?: Effect of Self-Avatar Appearance on Facilitating Realistic Behavior in Virtual Environments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376562},
doi = {10.1145/3313831.3376562},
abstract = {Preventing users from walking through virtual boundaries (e.g., walls) is an important issue to be addressed in room-scale virtual environments (VEs), considering the safety and design limitations. Sensory feedback from wall collisions has been shown to be effective; however, it can disrupt the immersion. We assumed that a greater sense of presence would discourage users from walking through walls and conducted a two-factor between-subjects experiment (N = 92) that controls the anthropomorphism (realistic or abstract) and visibility (full-body or hand-only) of self-avatars. We analyzed the participants' behaviors and the moment they first penetrated the wall in game-like VEs that gradually instigated participants to penetrate the walls. The results showed that the realistic full-body self-avatar was the most effective for discouraging the participants from penetrating the walls. Furthermore, the participants with lower presence tended to walk through the walls sooner. This study can contribute to applications that require realistic user responses in VEs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {body ownership, presence, self-avatar},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3311350.3347172,
author = {Krekhov, Andrey and Cmentowski, Sebastian and Emmerich, Katharina and Kr\"{u}ger, Jens},
title = {Beyond Human: Animals as an Escape from Stereotype Avatars in Virtual Reality Games},
year = {2019},
isbn = {9781450366885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3311350.3347172},
doi = {10.1145/3311350.3347172},
abstract = {Virtual reality setups are particularly suited to create a tight bond between players and their avatars up to a degree where we start perceiving the virtual representation as our own body. We hypothesize that such an illusion of virtual body ownership (IVBO) has a particularly high, yet overlooked potential for nonhumanoid avatars. To validate our claim, we use the example of three very different creatures---a scorpion, a rhino, and a bird---to explore possible avatar controls and game mechanics based on specific animal abilities. A quantitative evaluation underpins the high game enjoyment arising from embodying such nonhuman morphologies, including additional body parts and obtaining respective superhuman skills, which allows us to derive a set of novel design implications. Furthermore, the experiment reveals a correlation between IVBO and game enjoyment, which is a further indication that nonhumanoid creatures offer a meaningful design space for VR games worth further investigation.},
booktitle = {Proceedings of the Annual Symposium on Computer-Human Interaction in Play},
pages = {439–451},
numpages = {13},
keywords = {virtual reality games, virtual creatures, ivbo, avatar control, animal embodiment, animal avatars},
location = {Barcelona, Spain},
series = {CHI PLAY '19}
}

@article{10.1109/TVCG.2023.3247089,
author = {Mal, David and Wolf, Erik and D\"{o}llinger, Nina and Wienrich, Carolin and Latoschik, Marc Erich},
title = {The Impact of Avatar and Environment Congruence on Plausibility, Embodiment, Presence, and the Proteus Effect in Virtual Reality},
year = {2023},
issue_date = {May 2023},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {29},
number = {5},
issn = {1077-2626},
url = {https://doi.org/10.1109/TVCG.2023.3247089},
doi = {10.1109/TVCG.2023.3247089},
abstract = {Many studies show the significance of the Proteus effect for serious virtual reality applications. The present study extends the existing knowledge by considering the relationship (congruence) between the self-embodiment (avatar) and the virtual environment. We investigated the impact of avatar and environment types and their congruence on avatar plausibility, sense of embodiment, spatial presence, and the Proteus effect. In a $2times 2$ between-subjects design, participants embodied either an avatar in sports- or business wear in a semantic congruent or incongruent environment while performing lightweight exercises in virtual reality. The avatar-environment congruence significantly affected the avatar's plausibility but not the sense of embodiment or spatial presence. However, a significant Proteus effect emerged only for participants who reported a high feeling of (virtual) body ownership, indicating that a strong sense of having and owning a virtual body is key to facilitating the Proteus effect. We discuss the results assuming current theories of bottom-up and top-down determinants of the Proteus effect and thus contribute to understanding its underlying mechanisms and determinants.},
journal = {IEEE Transactions on Visualization and Computer Graphics},
month = may,
pages = {2358–2368},
numpages = {11}
}

@ARTICLE{10.3389/frvir.2020.575943,

AUTHOR={Peck, Tabitha C.  and Gonzalez-Franco, Mar },

TITLE={Avatar Embodiment. A Standardized Questionnaire},

JOURNAL={Frontiers in Virtual Reality},

VOLUME={Volume 1 - 2020},

YEAR={2021},

URL={https://www.frontiersin.org/journals/virtual-reality/articles/10.3389/frvir.2020.575943},

DOI={10.3389/frvir.2020.575943},

ISSN={2673-4192},

ABSTRACT={The aim of this paper is to further the understanding of embodiment by 1) analytically determining the components defining embodiment, 2) increasing comparability and standardization of the measurement of embodiment across experiments by providing a universal embodiment questionnaire that is validated and reliable, and 3) motivate researchers to use6a standardized questionnaire. In this paper we validate numerically and refine our previously proposed Embodiment Questionnaire. We collected data from nine experiments, with over 400 questionnaires, that used all or part of the original embodiment 25-item questionnaire. Analysis was performed to eliminate non-universal questions, redundant questions, and questions that were not strongly correlated with other questions. We further numerically categorized and weighted sub-scales and determined that embodiment is comprised of interrelated categories of Appearance, Response, Ownership, and Multi-Sensory. The final questionnaire consists of 16 questions and 4 interrelated sub-scales with high reliability within each sub-scale, Chronbach's alpha ranged from $.72$ to $.82$. Results of the original and refined questionnaire are compared over all nine experiments and in detail for n=101 participants.  The updated questionnaire produced a wider range of embodiment scores compared to the original questionnaire and was able to discern that  participants over 30 years of age have significantly lower embodiment scores compared to participants  under 30 years of age. Removed questions and further research of interest to the community are discussed.}}

@incollection{HART1988139,
title = {Development of NASA-TLX (Task Load Index): Results of Empirical and Theoretical Research},
editor = {Peter A. Hancock and Najmedin Meshkati},
series = {Advances in Psychology},
publisher = {North-Holland},
volume = {52},
pages = {139-183},
year = {1988},
booktitle = {Human Mental Workload},
issn = {0166-4115},
doi = {https://doi.org/10.1016/S0166-4115(08)62386-9},
url = {https://www.sciencedirect.com/science/article/pii/S0166411508623869},
author = {Sandra G. Hart and Lowell E. Staveland},
abstract = {The results of a multi-year research program to identify the factors associated with variations in subjective workload within and between different types of tasks are reviewed. Subjective evaluations of 10 workload-related factors were obtained from 16 different experiments. The experimental tasks included simple cognitive and manual control tasks, complex laboratory and supervisory control tasks, and aircraft simulation. Task-, behavior-, and subject-related correlates of subjective workload experiences varied as a function of difficulty manipulations within experiments, different sources of workload between experiments, and individual differences in workload definition. A multi-dimensional rating scale is proposed in which information about the magnitude and sources of six workload-related factors are combined to derive a sensitive and reliable estimate of workload.}
}

@Inbook{Deci1985,
author="Deci, Edward L.
and Ryan, Richard M.",
title="Toward an Organismic Integration Theory",
bookTitle="Intrinsic Motivation and Self-Determination in Human Behavior",
year="1985",
publisher="Springer US",
address="Boston, MA",
pages="113--148",
abstract="Organismic theories in psychology are constructed around two core notions: that behavior is regulated in part by internal structures that are elaborated through experience; and that human beings are by nature active. There is no place where these assumptions are more critical than in the area of development, for as we will see they are essential to an understanding of the ubiquitous phenomenon of children working eagerly and continually to master their internal and external environments.",
isbn="978-1-4899-2271-7",
doi="10.1007/978-1-4899-2271-7_5",
url="https://doi.org/10.1007/978-1-4899-2271-7_5"
}

@phdthesis{shine2016ursidae,
  author      = {Shine, Catherine Louise},
  title       = {{Ursidae} Locomotion: Right Down to the ``{Bear} {Bones}''},
  school      = {University of Idaho},
  year        = {2016},
  month       = {May},
  type        = {Dissertation},
  address     = {Moscow, Idaho},
  note        = {Major in Biology}
}

@article{10.1242/jeb.121806,
    author = {Shine, Catherine L. and Penberthy, Skylar and Robbins, Charles T. and Nelson, O. Lynne and McGowan, Craig P.},
    title = {Grizzly bear (Ursus arctos horribilis) locomotion: gaits and ground reaction forces},
    journal = {Journal of Experimental Biology},
    volume = {218},
    number = {19},
    pages = {3102-3109},
    year = {2015},
    month = {10},
    abstract = {Locomotion of plantigrade generalists has been relatively little studied compared with more specialised postures even though plantigrady is ancestral among quadrupeds. Bears (Ursidae) are a representative family for plantigrade carnivorans, they have the majority of the morphological characteristics identified for plantigrade species, and they have the full range of generalist behaviours. This study compared the locomotion of adult grizzly bears (Ursus arctos horribilis Linnaeus 1758), including stride parameters, gaits and analysis of three-dimensional ground reaction forces, with that of previously studied quadrupeds. At slow to moderate speeds, grizzly bears use walks, running walks and canters. Vertical ground reaction forces demonstrated the typical M-shaped curve for walks; however, this was significantly more pronounced in the hindlimb. The rate of force development was also significantly higher for the hindlimbs than for the forelimbs at all speeds. Mediolateral forces were significantly higher than would be expected for a large erect mammal, almost to the extent of a sprawling crocodilian. There may be morphological or energetic explanations for the use of the running walk rather than the trot. The high medial forces (produced from a lateral push by the animal) could be caused by frontal plane movement of the carpus and elbow by bears. Overall, while grizzly bears share some similarities with large cursorial species, their locomotor kinetics have unique characteristics. Additional studies are needed to determine whether these characters are a feature of all bears or plantigrade species.},
    issn = {0022-0949},
    doi = {10.1242/jeb.121806},
    url = {https://doi.org/10.1242/jeb.121806},
    eprint = {https://journals.biologists.com/jeb/article-pdf/218/19/3102/1915887/jeb121806.pdf},
}
@article{amaike2021,
author = {Amaike, Hayato and SASAKI, Motoki and TSUZUKI, Nao and KAYANO, Mitsunori and OISHI, Motoharu and YAMADA, Kazutaka and ENDO, Hideki and ANEZAKI, Tomoko and Matsumoto, Naoya and NAKASHITA, Rumiko and KUROE, Misako and TARU, Hajime and BANDO, Gen and IKETANI, Yuko and NAKAMURA, Ryohei and SATO, Nobutaka and FUKUI, Daisuke and KITAMURA, Nobuo},
year = {2021},
month = {06},
pages = {},
title = {Mobility of the forearm skeleton in the Asiatic black (Ursus thibetanus), brown (U. arctos) and polar (U. maritimus) bears},
volume = {83},
journal = {Journal of Veterinary Medical Science},
doi = {10.1292/jvms.21-0198}
}

@misc{adw_ursus_arctos,
  author       = {{Animal Diversity Web}},
  title        = {{Ursus arctos (brown bear)}},
  howpublished = {University of Michigan Museum of Zoology},
  url          = {https://animaldiversity.org/accounts/Ursus_arctos/},
  note         = {Accessed: 2025-12-10}
}

@article{bartareau2011,
author = {Bartareau, Tad and Cluff, Howard and Larter, Nicholas},
year = {2011},
month = {11},
pages = {1128-1135},
title = {Body length and mass growth of the brown bear (Ursus arctos) in northern Canada: model selection based on information theory and ontogeny of sexual size dimorphism},
volume = {89},
journal = {Canadian Journal of Zoology},
doi = {10.1139/z11-088}
}

@article{polly2007,
author = {Polly, Paul and Hall, Brian},
year = {2007},
month = {01},
pages = {245-268},
title = {Limbs in Mammalian Evolution},
journal = {Fins into Limbs: Evolution, Development and Transformation}
}

@article{pang2020,
author = {Pang, Zaixiang and Wang, Tongyu and Wang, Zhanli and Yu, Junzhi and Sun, Zhongbo and Liu, Shuai},
year = {2020},
month = {03},
pages = {2101},
title = {Design and Analysis of a Wearable Upper Limb Rehabilitation Robot with Characteristics of Tension Mechanism},
volume = {10},
journal = {Applied Sciences},
doi = {10.3390/app10062101}
}

@article{davis1949,
  title = {The Shoulder Architecture of Bears and Other Carnivores},
  author = {Davis, D. Dwight},
  journal = {Fieldiana: Zoology},
  number = {34},
  publisher = {Chicago Natural History Museum},
  year = {1949},
  month = {sep}
}

@article{10.1242/jeb.140681,
    author = {Shine, Catherine L. and Robbins, Charles T. and Nelson, O. Lynne and McGowan, Craig P.},
    title = {Grizzly bear (Ursus arctos horribilis) locomotion: forelimb joint mechanics across speed in the sagittal and frontal planes},
    journal = {Journal of Experimental Biology},
    volume = {220},
    number = {7},
    pages = {1322-1329},
    year = {2017},
    month = {04},
    abstract = {The majority of terrestrial locomotion studies have focused on parasagittal motion and paid less attention to forces or movement in the frontal plane. Our previous research has shown that grizzly bears produce higher medial ground reaction forces (lateral pushing from the animal) than would be expected for an upright mammal, suggesting frontal plane movement may be an important aspect of their locomotion. To examine this, we conducted an inverse dynamics analysis in the sagittal and frontal planes, using ground reaction forces and position data from three high-speed cameras of four adult female grizzly bears. Over the speed range collected, the bears used walks, running walks and canters. The scapulohumeral joint, wrist and the limb overall absorb energy (average total net work of the forelimb joints, −0.97 W kg−1). The scapulohumeral joint, elbow and total net work of the forelimb joints have negative relationships with speed, resulting in more energy absorbed by the forelimb at higher speeds (running walks and canters). The net joint moment and power curves maintain similar patterns across speed as in previously studied species, suggesting grizzly bears maintain similar joint dynamics to other mammalian quadrupeds. There is no significant relationship with net work and speed at any joint in the frontal plane. The total net work of the forelimb joints in the frontal plane was not significantly different from zero, suggesting that, despite the high medial ground reaction forces, the forelimb acts as a strut in that plane.},
    issn = {0022-0949},
    doi = {10.1242/jeb.140681},
    url = {https://doi.org/10.1242/jeb.140681},
    eprint = {https://journals.biologists.com/jeb/article-pdf/220/7/1322/1898778/jeb140681.pdf},
}



