姿勢が人間と異なるアバタの歩行動作：姿勢と操作方法の一致性が身体所有感と行為主体感に及ぼす相互作用効果
本研究では、人間とは歩行姿勢が違うアバタにおける、身体所有感(Sense of Body Ownership)や行為主体感における歩行時の身体的姿勢と歩行動作の整合性の相互作用効果について調べた。先行研究では、仮想身体化における動作の整合性（Khan et al., 2025 [1]）と四足姿勢（Krekhov et al., 2019 [2]）の重要性が示されているが、相互作用効果、および入力動作と動作姿勢のロコモーション時の検証は十分ではない。本研究では、姿勢と動作の認知的相互作用を検証するために、2x2の要因配置（姿勢：立位 vs 擬似四つん這い × 動作：人間的腕振り vs クマ的ローイング）を用いた。動作プロファイルは、クマ科の生体力学、特に Ursus arctos（ヒグマ）の蹠行性歩行と独特な肩甲骨の回転に基づいて、「整合的な」動作として定義した。実装したシステムは、身体所有感（SoBO）、主体感（SoA）、およびプロテウス効果を測定するための実験装置として用いた。
1. Introduction
仮想現実（VR）技術の発展により、ユーザーは仮想身体を通じて多様な体験が可能となった。VR研究は、視覚的な忠実度（Fidelity）の追求から、存在することの体験的忠実度、すなわち身体所有感（Sense of Body Ownership: SoBO）や行為主体感（Sense of Agency: SoA）へと焦点が移行してきた [12]。身体化の錯覚（Embodiment Illusion）とは、ユーザーが能動的・自発的な運動実行を通じて頭や手足を動かし、脳内の予測状態が感覚入力（視覚、固有受容感覚、聴覚など）から得られる情報と一致したとき生じる強力なVRの錯覚である [3]。この錯覚の強さは、「私がこの行動の開始者であり源である」という主体感に由来する [3]。身体化感覚（Sense of Embodiment: SoE）の主要な構成要素である身体所有感（SoBO）と行為主体感（SoA）は機能的に分離可能であり [5]、触覚刺激がなくても視覚情報と運動（固有受容感覚）の同期だけで身体所有感は形成される [4]。Sanchez-Vivesら [4] は、データグローブを用いた実験で、同期条件（実際の手の動きがリアルタイムで仮想の手を駆動）と非同期条件（事前録画された動きを再生）を比較し、所有感に関する質問項目が同期条件で有意に高い値を示すこと（p=0.003）、固有受容感覚的変位（手の位置知覚のずれ）の中央値に3.5cmの有意な差があること（p=0.017）、さらに所有感と変位量の間に有意な正の相関（r=0.57）があることを実証した。
VR空間における移動（ロコモーション）手法も身体化に影響を与える重要な要素である。従来の研究では、その場歩き（Walking-in-Place）[7]、コントローラー/ジョイスティック [19]、テレポート [20] など多様な手法が提案されてきた。その場歩きは固有受容情報と感覚フィードバックの一致により存在感を高め [7]、腕振り移動はジョイスティックよりも優れた空間認識を提供する [8]。広大な物理空間での自然な歩行はテレポートよりもユーザー体験として優れ、VR酔いも少ない [18]。
ここで重要なのは、アバターの可視性と身体化の関係である。VRアクションゲームにおける研究では、多くのVRゲームが消費者向け全身モーションキャプチャデバイスの制約により、浮遊した仮想の手だけでユーザーを表現している [16]。興味深いことに、ゲーム文脈では表示される身体部分が増えても身体所有感、没入感、パフォーマンスに有意な差は見られず、見た目よりも「自分の思った通りに手が動くか（主体感）」がより重要であることが示唆されている [16]。移動技術と身体所有感の関係についても、アバターを身体化している場合、どの技術を用いても参加者は同程度の身体所有感を持つことが報告されている [17]。これらの知見は、身体化において視覚的な完全性よりも運動と感覚の同期が本質的に重要であることを示している。
VR技術の進歩に伴い、人間型（擬人化）アバタを超えて、動物、空想上の生物、抽象的な形状など、非人間型の形態への身体化を通じて、人体スキーマの可塑性を探求する研究が進められている [13][22][26]。非人間型アバタには動物だけでなく植物（木など）も含まれ、VRを通じて木の身体化を経験することで没入感や自然との関連性が促進されることが報告されている [22]。動物の身体化に関しては、牛やサンゴのアバターを用いた研究で、感覚豊かなVRでの身体化体験がビデオ視聴に比べて高い身体化感覚、実在感、そして自然との相互接続感をもたらすことが示されている [13]。ペンギンへの身体化研究では、VRでの身体化の強さと体験後の共感度に有意な相関関係が見られ、非人間キャラクターへの身体化が教育や生物への理解促進において強力なツールとなりうることが実証されている [26]。
多様な形態に宿るこの能力は、ユーザーが自身のデジタル表現の知覚された特性に合わせて行動や認知を変容させる「プロテウス効果」を誘発する [3][25][30]。プロテウス効果のメカニズムについては、没入型VR、仮想環境、およびアバターの使用がユーザーに没個性化の感覚を引き起こし、アバターの外見によって喚起される行動的および態度的期待に同調しやすくなるという見解が提案されている [30]。また、アバターの外見と行動の不一致を避けようとする認知的不協和の心理が働くとも仮定されている [30]。非人間型アバターにおいてもプロテウス効果が確認されており、魅力的な非人間型アバターを体現した参加者は、自己類似性を通じたアバターへの同一視をより高く知覚し、社会的参加が増加することが示されている [25]。
しかし、非人間型アバタにおいて強固な身体化感覚を達成するには、人間の運動学を非人間の生体力学にマッピングするという独自の課題が存在する [9][10][14]。動物は関節の数や構造（形態）が人間と異なるため、「人間のどの部位を動物のどの部位に対応させるか」という正解がない [14]。ユーザーの手の高い器用さと協調性を活用し、自動生成された関節間マッピングを通じて非ヒューマノイドアバターを制御する手法も提案されている [9]。一方、全身を使って多様な静的メッシュをアニメーション化できるが、全身での非人間アバタ操作は負荷が高いという課題がある [10]。
現在の文献は、非人間型アバタにおける身体化の主要な推進要因として、動作の整合性（Motion Congruence）と身体的姿勢（Physical Posture）の2つを特定している。Khanら（2025）[1] は、アバタの外見と移動方法の間の整合性（congruence）がアバタへの同一視（avatar identification）とユーザー体験を有意に向上させることを実証した。これとは独立して、Krekhovら（2019）[2] は身体的姿勢の重要性を強調し、アバタと整合した姿勢をとることが非人間型であっても強力な身体所有感を引き出せることを示した。
これらの進展にもかかわらず、姿勢と動作の整合性の間の相互作用効果、および入力動作と動作姿勢のロコモーション時の検証が十分ではない。整合的な姿勢をとることは、単に身体化スコアを加算するだけなのか、それとも整合的な動作の認知的効果を増幅させる乗数として機能するのか？本研究では以下の研究課題を設定し、検証する。
RQ1: 四足歩行動物アバタでのロコモーション環境下において、ユーザの物理的な姿勢（擬似四つん這い vs 立位）は、アバタへの自己認識（身体所有感、行為主体感）に影響を与えるか？
RQ2: 四足歩行動物アバタでのロコモーション環境下において、操作のマッピング一致性（動物らしい vs 人間らしい）は、自己認識に影響を与えるか？
RQ3: マッピング一致性が自己認識に与える影響の度合いは、ユーザーの物理的な姿勢によって変わるか？（『擬似四つん這い』の時だけ、『動物らしい操作』の効果が特に強まる？）
Khanら [1] の「整合性」フレームワークと Krekhovら [2] の「姿勢」フレームワークを統合し、両者を Ursus arctos の生物学的現実に基づかせることで、非人間型身体化の基礎となるメカニズムについて詳しく検討する。

2. Related Work
2.1 人型アバタへの身体化
VRにおける身体化の錯覚は、脳の予測符号化（Predictive Coding）メカニズムに基づいているといわれている [3]。ユーザーが能動的・自発的な運動実行を通じて頭や手足を動かし、脳内の予測状態が感覚入力と一致したとき、強力なVRの錯覚が生じる。不一致な感覚入力は、予測された世界の状態を確認するために再調整または抑制され、脳は予測された結果への優先傾向を強化するために感覚入力の方に誤りがあると「決定」することができる [3]。これらのトップダウンの主体感メカニズムは、特定の状況下で遅延（最大200msまで）への許容度を高めることが示されている。
身体化感覚は、身体所有感（SoBO）と行為主体感（SoA）という代表的な2つの構成要素を含む [12]。SoAとSoBOは機能的に分離可能であり、バーチャルな手を不一致な物体に置き換えても、リアルタイムの自発的な動きが保たれていれば潜在的なSoAは維持される [5]。参加者は、現実とバーチャルの動きの間の視覚運動整合性が保たれていれば、非身体的な物体に対してさえSoAを経験することができる [5]。また、触覚刺激がなくても、視覚情報と運動の同期だけで身体所有感の錯覚は形成される [4]。Sanchez-Vivesらの研究 [4] では、180秒間の視覚運動同期刺激の後、仮想の手が20秒かけて約20cm移動したにもかかわらず、被験者は自分の手が動いていないことを知りながらも、手の位置を仮想の手の方向に誤認した。これは、視覚と固有受容感覚が視覚優位で統合されると、視覚的要素の移動が固有受容感覚的要素の移動も引き起こすことを示している。さらに重要な知見として、指の視覚触覚相関は個々の指の錯覚的変位を誘発するのに対し、指の動きの視覚運動相関は腕全体の錯覚的変位を誘発し、より全体的で断片化されていない身体所有感を生成することが報告されている [4]。VRにおいて「リアルタイム」かつ「タスクの邪魔にならない」評価手法が身体化の測定において最も重要とされている [12]。認知に影響を与えるには、単なる視覚的フィードバックではなく、多感覚的な体験すなわち感覚運動フィードバックが必要である可能性がある [28]。
子供と成人を対象とした研究では、動きの同期（視覚運動同期）とアバターの外見が身体所有感と主体感に影響を与えることが確認されている [23]。動きが遅れる（非同期）ほど、また外見が人間らしくないほど、所有感は減少するが、子供は成人より悪条件の影響を受けにくいことが示されている [23]。アバターの外見のリアリズムと類似性は身体所有感にとって重要であり、ユーザー自身の顔に似たアバターを使用することでEmbodimentとPresenceが促進される [24]。
視点の選択も身体化に影響を与える。一人称視点と三人称視点の比較研究では、ナビゲーションタスクには一人称視点の方が適していることが示されており、三人称視点がリアルな表現と組み合わされたときのみ、一人称視点と同様の身体所有感と空間認識が得られることがわかっている [21]。
VR空間内での移動手法は多様化している。従来はコントローラーベースの移動が主流であり [19]、主要な手法として、その場歩き（Walking-in-Place）、コントローラー/ジョイスティック、テレポートの3つが存在する [20]。その場歩きは、人間の体の動きから得られる固有受容情報とディスプレイからの感覚フィードバックの一致が強いほど仮想環境での存在感が増すという考えに基づいているといわれている [7]。腕振り移動は、高価な歩行トラッキングシステムの代わりに安価なウェアラブルデバイスを使用し、ジョイスティックよりも優れた空間認識を提供できる [8]。広大な物理空間での自然な歩行はテレポートよりもユーザー体験として優れており、VR酔いも少ない [18]。移動技術と身体所有感の関係については、アバターを身体化している場合、どの技術を用いても参加者は同程度の身体所有感を持つことが報告されている [17]。ローイングマシンを用いたVR移動研究では、頭、手、足の動きに基づいた操縦技術が2Dおよび3D VR環境向けに実装されている [11]。
VR空間におけるアバターが現実の物理法則に従って動くことも、身体所有感に影響を与える [6]。ユーザーの動きとの同期（1対1のマッピング）を多少犠牲にしても、環境に対して物理的に正しく反応する方が、VR体験における身体性を向上させることが示されている [6]。物理対応アバターは、単なる身体認識だけでなく、周囲の環境との関係性（Environment Awareness）をユーザーに提供する [6]。自己アバターの見た目（リアリズムと身体の可視性）は、ユーザーの現実的な振る舞いにも影響し、リアルな全身アバターが参加者の壁抜けを抑制するのに最も効果的であることが示されている [29]。

2.2 非人間型アバタへの身体化
非人間型アバタへの身体化研究は、動物から植物まで多様な形態を対象としている。動物の身体化に関しては、Ahn et al.による牛やサンゴのアバターを用いた研究で、VRでの身体化体験がビデオ視聴に比べて高い身体化感覚と自然との相互接続感をもたらすことが示されている [13]。この研究では、参加者は四つん這いになり牧草地で牛の視点を体験し、仮想空間で電気棒で突かれると触覚フィードバックが与えられた。VR体験と自己への自然の包含（INS）の関係を媒介していたのは、空間的実在感ではなく身体転送感のみであった [13]。植物（木）の身体化研究では、iVRを通じて木の身体化を経験することが没入感、自然との関連性、視点取得、人間と自然の関係についての省察を促進するかが調査されている [22]。参加者が体験に没入していると感じるほど、自然との関連性のレベルが高まることが報告されている [22]。ペンギンへの身体化研究では、VRでの身体化の強さと体験後の共感度に有意な相関関係が見られ、非人間キャラクターへの身体化が教育や生物への理解促進において強力なツールとなりうることが実証されている [26]。
人間以外のキャラクターをリアルタイムに操作するパペトリーシステムでは、身体構造や動作パターンが人間と大きく異なる様々なクリーチャーの制御が試みられている [14]。動物やクリーチャーは関節の数や形態が人間と異なるため、人間とクリーチャー間の身体対応関係の設計は曖昧で非自明なタスクである [14]。直接特徴マッピング手法では最適な人間-クリーチャー間の身体対応関係が選択され、人間が物理的に真似できない動きについてはモーションカップリングが使用される [14]。HandAvatarは、ユーザーの手の高い器用さと協調性を活用し、自動生成された関節間マッピングを通じて非ヒューマノイドアバターを制御する手法を提案しており、全身ではなく手のみを使用することで操作負荷を軽減している [9]。KinEtreは全身を使って多様な静的メッシュをアニメーション化できるが、全身での非人間アバタ操作は負荷が高いという課題がある [10]。
Krekhovら（2019）[15] は、仮想の身体所有感（IVBO）が人間型ではないアバターにおいて特に高い潜在能力を持つと仮説を立て、サイ、蠍、鳥などの動物アバターを用いた実験で仮想の身体所有感とゲームの楽しさとの間に相関関係があることを明らかにした。興味深いことに、必ずしもリアルな姿勢（例：四つん這い）である必要はなく、立位でサソリを操作するようなマッピングでも十分に直感的で楽しめることが示されている [15]。
プロテウス効果とは、ユーザーが自身のデジタル表現の知覚された特性に合わせて行動や認知を変容させる現象である [3][25][30]。仮想環境において、人々は自分が体現しているバーチャルアバターの特徴に沿った行動をとる傾向がある [25]。プロテウス効果のメカニズムについては、没入型VRとアバターの使用がユーザーに没個性化の感覚を引き起こし、アバターの外見によって喚起される行動的・態度的期待に同調しやすくなるという見解が提案されている [30]。また、アバターの外見と行動の不一致を避けようとする認知的不協和の心理も働く [30]。非人間型アバターにおいてもプロテウス効果は確認されており、魅力的な非人間型アバターを体現した参加者は、自己類似性を通じたアバターへの同一視をより高く知覚し、社会的参加が増加する [25]。アバターと環境の適合性に関しては、両者が一致している場合にシミュレーションのもっともらしさ（特に外的整合性）の評価が有意に高まるが、プロテウス効果は環境の違いによって変化せず、自分がどのような姿をしているかが行動変容の要因としてより強力である可能性が示唆されている [27]。身体化やプレゼンスは条件に関わらず全体的に高いスコアを示し、多少の文脈不一致があっても基本的な身体所有感は損なわれない [27]。
2.3 姿勢と入力動作の一致性
非人間型アバタにおける身体化の推進要因として、動作の整合性（Motion Congruence）と身体的姿勢（Physical Posture）が特定されている。本節では、これらの要因に関する2つの重要な先行研究について詳述する。
Khanら（2025）[1] は、アバタの外見と移動方法の整合性（Avatar-Locomotion Congruence）がユーザー体験とアバタへの同一視（avatar identification）に与える影響を調査した。彼らは30名の参加者を対象に被験者内実験を実施し、2種類のアバタ（ゴリラと人間）と2種類の移動方法（ゴリラ的なアームローリングと人間的な腕振り）を用いた。アームローリングは人気のソーシャルVRゲーム「Gorilla Tag」に触発されたもので、ユーザーの視点は地面に近く設定され、仮想の手が地面に接触してゴリラの四足歩行を模倣する。ユーザーは地面に対して手を引いたり押したりすることで、シミュレートされた力を発生させ運動量を生成する。一方、腕振り移動はパルクールゲーム「Stride」などで使用されており、ユーザーの視点はより高く設定され、自然な歩行動作で腕を振ることで移動する。実験の結果、アバタの外見と移動方法が整合している条件（ゴリラ×アームローリング、人間×腕振り）において、アバタへの同一視（wishful identification、embodied presence、similarity identification）とユーザー体験（enjoyment、satisfaction、ease of learning）が有意に向上することが明らかになった。特に、ゴリラアバタとアームローリングの組み合わせは、他の条件と比較して高い楽しさと満足度を示した。また、整合条件では学習のしやすさが向上し、不整合条件（例：ゴリラ×腕振り）ではより急な学習曲線が観察された。参加者からは「マッチした移動方法を持つアバタは、キャラクターとのつながりをより感じさせた」「鏡でゴリラとしての自分を見ると、もっとゴリラのように振る舞いたくなった」といったフィードバックが得られている。ただし、Khanらの研究ではユーザーは常に直立姿勢でVR体験を行っており、身体的姿勢の変化（例：四つん這い）については検討されていない。
Krekhovら（2019）[2] は、仮想の身体所有感の錯覚（Illusion of Virtual Body Ownership: IVBO）が非人間型アバターにも適用可能かを探求した。彼らは26名の参加者を対象に被験者内実験を実施し、人間の身体とは骨格、姿勢、形状が異なる3種類の動物アバター（コウモリ、トラ、クモ）と人間アバターを比較した。動物の選定理由として、コウモリは人間と姿勢・骨格が類似しているが形状（プロポーション）が異なり、トラは骨格は類似しているが四足歩行という姿勢が異なり、クモは8本の脚を持つという骨格自体が大きく異なる。実験では、複数のボディマッピング手法が検証された。Full-body（FB）トラッキングではユーザーの姿勢が動物の全身にマッピングされ、half-body（HB）トラッキングではユーザーが直立姿勢を維持したまま下半身の動きのみを動物の全肢にマッピングする（例：人間の片脚がトラの2本の脚に対応）。また、一人称視点と三人称視点の比較も行われた。
実験の結果、IVBOは非人間型アバターにも適用可能であり、特にコウモリアバターはacceptance（受容）とcontrol（制御）の次元において人間アバターを有意に上回るスコアを獲得した。これは、人間に類似した直立姿勢と骨格を持つ動物がIVBOを誘発しやすいことを示唆している。重要な知見として、FBトラッキングとHBトラッキングの間でIVBOスコアに有意差は見られなかった。つまり、1:1の全身マッピングはIVBOの必要条件ではなく、HBアプローチでも同等のIVBO効果が得られることが示された。一方、FBモードでトラやクモを操作する場合、ユーザーは床に這いつくばる必要があり、著しい疲労が報告された。HBモードはこの疲労を大幅に軽減しつつIVBOレベルを維持できるため、直立姿勢でない動物には有効な代替手段となる。また、一人称視点は三人称視点よりもIVBOにおいて優れていることが確認された。ただし、Krekhovらの研究は主にアバター操作の静的または半静的な姿勢の一致に焦点を当てており、移動時の動作の運動学については深く調査されていない。
これら2つの研究は、それぞれ動作の整合性と身体的姿勢の重要性を独立に示しているが、両者の相互作用については検討されていない。本研究ではこれを拡張し、姿勢は単なる静的変数ではなく、移動中の動的な有効化要因であると考える。ユーザーがアバタの方向と整合した姿勢をとることで、運動指令をアバタの動きに変換するために必要な認知的負荷が軽減され、整合的な動作パターンの効果が増幅される可能性がある [1][3]。さらに、動物アバタにおける「整合的な動作」は、厳密な生物学的データから導き出されるのではなく、デザイナーによって近似的に設定されることが多いという問題もある [14]。本研究では、Ursus arctos（ヒグマ）の生体力学的データに基づいて整合的な動作を定義することで、この問題に対処する。

3. ユーザスタディ

3.1 参加者
本研究では、n名の参加者（男性n名、女性n名、平均年齢n歳、SD=n、範囲n-n歳）を対象に実験を実施した。参加者は全員、大学の学部生および大学院生である（実験時間：約60分）。

参加者の身長は平均n cm（SD=n、範囲n-n cm）であった。本研究では擬似四つん這い姿勢と立位姿勢の両条件を実施するため、身長は視点の高さの個人差に影響する可能性がある。ただし、VR空間内のカメラ位置は各条件で固定値（亜成体クマ条件：0.7 m、成体クマ条件：1.6 m）に設定されているため、参加者間の身長差がアバターの視点体験に直接影響することはない。

VRおよびHMDの使用経験について7段階尺度（1: 全くない、7: 専門家レベル）で尋ねた結果、中程度の経験レベルであった（M=n、SD=n）。
3.2 研究デザインと仮説
本研究では、被験者内計画（within-subjects design）を採用し、姿勢（Posture）とマッピング方法（Mapping Method）の2つの独立変数を設定した。各参加者は、これらの条件のすべての組み合わせをラテン方格法（Latin Square design）を用いてカウンターバランスした順序で体験した。実験条件は以下の4つである：

[image1: 4つの実験条件を示す図。C1からC4まで、アバターの姿勢とマッピング方法の組み合わせを視覚的に表現]

• C1（亜成体クマ × 高一致性マッピング）: 参加者は擬似四つん這い姿勢をとり、クマ的ローイング動作（高一致性）で移動する。視点の高さは亜成体クマの視点と一致。
• C2（亜成体クマ × 低一致性マッピング）: 参加者は擬似四つん這い姿勢をとり、人間的腕振り動作（低一致性）で移動する。視点の高さは亜成体クマの視点と一致。
• C3（成体クマ × 高一致性マッピング）: 参加者は立位姿勢をとり、クマ的ローイング動作（高一致性）で移動する。視点の高さは成体クマの視点と一致。
• C4（成体クマ × 低一致性マッピング）: 参加者は立位姿勢をとり、人間的腕振り動作（低一致性）で移動する。視点の高さは成体クマの視点と一致。

亜成体クマとは、成体クマに比べて小型であり、視点の高さも低い。生物学的にクマの亜成体とは、生後2〜5年目の個体を指す。成体クマは5歳以上の個体であり、体格が大きく視点の高さも高い。[36-2]

ここで、擬似四つん這い姿勢は、参加者が両手と両膝を地面に接触させ、背中を水平に保つことで実現される。この姿勢は、クマの四足歩行の動作パターンを模倣することを目的としている。一方、立位姿勢では、参加者は自然な直立姿勢を維持する。
クマ的ローイング動作は、Ursus arctosの生体力学データに基づいて設計されており、参加者は両手を前後に動かすことで前進する。一方、人間的腕振り動作では、参加者は自然な歩行時の腕振り動作を模倣する。
また、視点の高さは、亜成体クマ条件では地面から0.7メートル、成体クマ条件では1.6メートルに設定された。これにより、参加者は各姿勢においてクマの視点を体験できる。

本研究の主要な目的は、ユーザーの物理的な姿勢（立位 vs 擬似四つん這い）と操作マッピング方法（クマ的 vs 人間的）が、身体所有感、行為主体感、疲労度、および全体的なユーザー体験に与える影響を比較検証することである。

以下の仮説を設定した：

H1: クマ的ローイング動作（高一致性マッピング）は、人間的腕振り動作（低一致性マッピング）よりも高い身体所有感（SoBO）と行為主体感（SoA）をもたらす。

H2: 擬似四つん這い姿勢は、立位姿勢よりも高い身体所有感をもたらす。

H3: 姿勢と動作マッピングの間には交互作用効果が存在する。具体的には、擬似四つん這い姿勢において、動作の整合性（クマ的ローイング vs 人間的腕振り）が身体所有感と行為主体感に与える効果は、立位姿勢よりも大きくなる。

3.3 手順
実験室に到着後、参加者には同意書を読んで署名してもらった。その後、実験前アンケートに回答し、人口統計情報および感覚・運動障害の有無を報告してもらった。

[image2: 実験環境の写真。参加者がHMDを装着している様子]

実験者は、クマ的動作と人間的腕振り動作の使用方法について説明した。参加者はすべての移動方法を練習し、現実の世界で最大3分間の時間が設けられた。これは、実験の本番前にアバターへの露出によるバイアスを制限するための設計である。

学習フェーズが完了すると、実験者は残りの手順について参加者に説明した。これは、HMDを再び装着し、3.2で説明した4つの条件に対応する、開発されたプログラムの4つのバージョンを体験することで構成された。参加者がこれらの4つの条件を体験する順序は、順序バイアスを避けるためにラテン方格法によってカウンターバランスされた。

各条件において、参加者は2分間VR空間内で過ごした。この間、参加者は十分に広いオープンワールドの草原の仮想環境で移動タスクを体験した。移動フェーズでは、参加者は前方視野角120度の範囲内で視線を向けることが求められ、上下方向への視線移動は許可された。シーン上に提示された目標ポイントに向かって前進することがタスクとして与えられたが、目標ポイントを超えることも、到達しないことも許容された。このタスクの主目的は、参加者がクマのように歩行できるかを評価することであった。

[image4: VR空間内のオープンワールド草原環境の様子。広大な草原に目標ポイントが提示されている]

2分間が経過した後、実験者は参加者にHMDを外すよう依頼し、アンケートに回答してもらった。このプロセスは、4つの条件すべてに対して繰り返された。各条件の完了後、参加者には2分間の休憩時間が与えられた。休憩が不十分であると感じた場合は、参加者に追加の休憩時間を申し出るよう促した。

4つの条件すべてが完了した後、参加者には実験全体を通じてのコメントを尋ね、実験を終了した。

3.4 測定項目
本研究では、アバターへの身体化、ユーザー体験、およびプロテウス効果を測定するために、複数の標準化された質問紙を使用した。

アバターへの身体化を測定するために、Peck \& Gonzalez-Franco（2021）によって検証・標準化されたAvatar Embodiment質問紙を使用した [31]。この質問紙は、9つの実験から収集された443件以上の回答データに基づく探索的因子分析により、当初の25項目から16項目に精緻化されたものである。分析の結果、身体化は相互に関連する4つのサブスケールで構成されることが示された：Appearance（外見）、Response（応答性）、Ownership（身体所有感）、Multi-Sensory（多感覚統合）。各サブスケールは高い信頼性を示し（Cronbach's α = 0.72--0.82）、改訂版質問紙は元の質問紙と比較してより広いスコア範囲を提供し、個人差の検出に優れることが検証されている [31]。本研究では、この質問紙の16項目のうち、クマアバターの特性に適合する6項目を選択して使用した。各項目は7段階のリッカート尺度（1: 全くそう思わない、7: 非常に強くそう思う）で評価された。これらの項目から、身体所有感（SoBO）と行為主体感（SoA）のスコアを算出した。

タスク負荷を測定するために、NASA-TLXを使用した [32]。NASA-TLXは、知的要求、身体的要求、時間的切迫感、遂行成績、努力、フラストレーションの6つの次元から構成される。各次元は0か20の範囲で評価される。

ユーザー体験を測定するために、複数の標準化された尺度を採用した。Khanら（2025）[1] の研究では、アバターと移動方法の整合性が身体化だけでなく、楽しさ（enjoyment）、満足度（satisfaction）、学習のしやすさ（ease of learning）といったユーザー体験にも有意な影響を与えることが示されている。本研究でも同様に、姿勢と動作マッピングの整合性がユーザー体験に与える影響を検証するため、楽しさ（Enjoyment）と能力感（Competence）をIntrinsic Motivation Inventory（IMI）[33] から評価した。楽しさは、VR体験における内発的動機づけの中核的要素であり、身体化の質と関連することが示唆されている。能力感は、ユーザーがアバターを効果的に操作できているという主観的評価を反映し、特に新規の動作マッピング（クマ的動作）の習得しやすさを評価する上で重要である。各項目は7段階のリッカート尺度（1: 全くそう思わない、7: 非常に強くそう思う）で評価された。

アバターの身体的特性に関する知覚を評価するために、クマの典型的な身体能力(速度、身体サイズ、重量、力強さ)に関する項目を作成した。本研究では、クマアバターへの身体化が、参加者自身の身体能力の知覚をクマの特性に近づけるかどうかを検証するため、これらの項目を設定した。速度は、ロコモーション体験において最も直接的に知覚される運動特性であり、移動速度の変化がアバターとしての移動能力の認識に影響を与える。身体サイズと重量は、クマの物理的存在感を表す基本的な属性であり、視点の高さや視覚的フィードバックを通じて知覚される身体スケールの変化を捉える。力強さは、四足歩行における前肢の推進力生成と関連し、特にクマ的動作における地面を押す動作が、力の行使感覚を強化すると予測される。これらの項目は、ロコモーションの身体化が単なる運動制御にとどまらず、アバターの身体的属性全体の内在化をもたらすかを評価するために選定された。特に、ロコモーションマッピングの一致性が高い条件では、アバターの身体的特徴がより強く内在化され、プロテウス効果が増強されると予測される。各項目は7段階のリッカート尺度(1: 全くそう思わない、7: 非常に強くそう思う)で評価された。

4. システム詳細

4.1 クマを選定した理由
本研究でクマ科動物をアバターとして選択した理由は、以下の生物学的および実験的な根拠に基づいている。

クマ科動物は、人間とは異なる四足歩行を行うが、骨格構造や関節の動きにおいて人間との類似性を持つ。特に、クマは蹠行性（plantigrade）歩行を行う大型哺乳類であり、人間と同様に足裏全体を地面に接地して歩行する [35]。この蹠行性の特性により、人間の手の動きをクマの前肢の動きに自然にマッピングすることが可能となる。これは、ユーザーの手の動きをクマの前肢にマッピングする際、感覚的な対応関係が存在することを示唆している。

ヒグマ（Ursus arctos）の肩高は、成体で90～150 cmの範囲にある [36-1]。本研究では、この成長段階による体格差を利用して視点の高さを操作した。亜成体クマを想定した条件では、肩高を約60-80 cmに設定し、これは人間が擬似四つん這い姿勢をとったときの目の高さとほぼ一致する。一方、成体クマを想定した条件では、肩高を90-120 cm程度に設定し、これは人間が立位姿勢をとったときの目の高さ（約150-170 cm）に対応するよう、VR空間内でのカメラ位置を調整した [36-2]。この設計により、同じクマ科アバターを使用しながら、成長段階を変えることで視点の高さを操作し、姿勢条件（擬似四つん這い vs 立位）に応じた適切な視覚体験を提供することができる。

[image5: 亜成体クマと成体クマの肩高と視点の高さを示す図。人間の擬似四つん這い姿勢と立位姿勢との対応関係を視覚的に表現]

非人間型アバターにおける身体所有感の研究によれば、全身を表示する必要はないが、操作可能な身体部位を視界に入れることが重要であることが示されている [15]。この知見に基づき、本研究ではクマの前肢(操作に直接関与する部位)のみを視界内に提示する設計を採用した。この設計により、前肢の動きと視覚フィードバックの整合性を最大化し、強固な身体所有感を誘発することが可能となる。

以上より、クマを選択することで、蹠行性歩行による人間との骨格的類似性、成長段階による視点の高さの操作性、および前肢を中心とした操作可視性を同時に満たした状態でロコモーション実験を実施できる。

4.2 クマの前肢の生体力学

非人間型アバターの制御において、人間の運動学を非人間の生体力学にマッピングすることは本質的に困難である [9][10][14]。動物は関節の数や構造（形態）が人間と異なるため、「人間のどの部位を動物のどの部位に対応させるか」という正解が存在しない [14]。全身を使って非人間アバターを操作する手法も提案されているが、全身トラッキングの技術的制約や身体的負荷が課題となる [10]。

本研究では、この課題に対して、前肢のみの操作で四足歩行を実現するという設計方針を採用した。クマの四足歩行において、前肢は体重の54-60%を支持し、全速度域において制動力(braking impulse)は後肢より有意に大きく、一方で推進力(propulsive impulse)は前肢と後肢で有意差がない [44]。この力学的特性から、前肢は歩容の制御において中心的な役割を果たすことが示されている。人間の手をクマの前肢の先にマッピングし、腕の動きはIKソルバーによって自動生成することで、限られた入力から前脚全体の協調運動を実現する。この設計により、ユーザーは前肢の制御に認知資源を集中でき、クマとしての移動体験に没入しやすくなる。

人間の手の動きをクマの前肢にマッピングする際、前腕部の橈骨（radius）と尺骨（ulna）における回内・回外運動（pronation/supination）の可動性が重要な設計根拠となる。Amaikeら（2021）の研究によれば、ヒグマ（U. arctos）の亜成体では前腕の回内・回外角度が約70-80度と大きく、これは人間の前腕の可動域（約140-160度）の約半分に相当する [40]。一方、ヒグマ成体およびホッキョクグマ（U. maritimus）成体では約40-50度と有意に小さい [40]。重要な点として、クマ科では最大回内位置が通常の接地姿勢（手掌を地面に向けた状態）とほぼ一致するため、VRにおいて人間の手のひらを下向きに構えた自然な姿勢が、クマの前肢の接地姿勢に直接対応する [40]。

また、クマは蹠行性（plantigrade）の姿勢を持つ哺乳類であり、手根骨（carpals）と足根骨（tarsals）を基質に接触させた状態で立つ [43]。蹠行性の姿勢は、趾行性や蹄行性（unguligrade）の哺乳類と比較して、前肢による前方推進力の生成により大きく寄与できるという機能的利点を持つ [43]。クマのような蹠行性哺乳類は、手のひら全体を使って地面と接触することで、足部を前方推進のためにより効果的に使用できる [43]。この蹠行性の特性は、VRにおいて人間の手の動きをクマの前肢にマッピングする際の重要な生体力学的根拠となる。人間も蹠行性であり、手のひら全体で基質を支持する能力を持つため、クマの前肢の接地動作を直感的に再現できる身体構造的基盤が存在する [43]。

これらの生物学的観点を組み合わせることで、ユーザーのクマ的動作では、手のひらを下向きに向けた状態で、手を前方に伸ばし、地面を押すように後方に引く動作を繰り返すことで、クマの前肢が最大回内位置で接地し、手のひら全体で地面を押すという蹠行性の推進メカニズムに基づいたクマ的操作が可能になる。

重要な点として、クマの前肢と人間の上肢は、肩関節、肘関節、手根関節という三つの主要な関節を共有しており、運動自由度において構造的類似性を持つ [x]。この類似性により、人間の手と腕の動きをクマの前肢にマッピングすることが解剖学的に妥当となる。

4.3 ロコモーションの実装

人間的腕振り動作は、標準的な「その場ジョギング」ロジックに基づいている。システムはMeta Quest 3コントローラーの垂直速度ベクトル（$V_y$）を監視する。コントローラーの上下運動が閾値（$V_{threshold} = 0.5$ m/s）を超えると、前方への速度が適用される

$$v_{forward} = k_{swing} \cdot |V_y|$$

ここで、$k_{swing}$は速度変換係数（$k_{swing} = 2.0$）である。このマッピングは、人間の二足歩行における腕振りを、クマの前肢の動きに直接マッピングする。ナビゲーションとしては機能的に有効だが、クマの生体力学とは一致せず、対照条件として機能する。

実験時の教示では、参加者に「自然に歩くときのように腕を前後に振ってください」と指示した。この動作は人間にとって極めて直感的であり、特別な練習を必要としない。ユーザーは立位または座位のまま、通常の歩行リズムで腕を振ることで移動できる。この条件は、動作の直感性は高いが、クマの実際の前肢運動パターンとは乖離しているため、低一致性マッピングとして位置づけられる。

[image6: 人間的腕振り動作のマッピングを示す図。コントローラーの垂直方向の動きと、アバターの前進速度の関係を視覚的に表現]

クマ的動作は、4.2節で述べた前肢の生体力学的特性に基づいて設計された。本研究の実装では、コントローラーの前後方向の速度（$V_z$）と垂直位置（$P_y$）を追跡する。コントローラーが胸の高さの閾値（$H_{chest} = 0.8$ m）より低い位置で後方へ移動（$V_z < -0.3$ m/s）した際、推進力が生成される：

$$v_{power} = k_{power} \cdot |V_z| \cdot (1 - \frac{P_y}{H_{chest}})$$

ここで、$k_{power}$は変換係数（$k_{power} = 3.0$）であり、$(1 - \frac{P_y}{H_{chest}})$は位置に応じた重み付け項である。手が低い位置にあるほど、より大きな推進力が生成される。

コントローラーが胸の高さの閾値より高い位置で前方へ移動（$V_z > 0.2$ m/s）した際は、推進力は生成されず、次の推進動作の準備となる。

実験時の教示では、参加者に「姿勢を前方重心に、手を前に出してから後ろに引いてください。」と指示した。この教示は、4.2節で述べたクマの前肢における回内位置での接地と、蹠行性による推進メカニズムを、ユーザーが直感的に再現できるよう設計されている。

[image7: クマ的ローイング動作のマッピングを示す図。コントローラーの前後方向の動きと、アバターの前進速度の関係を視覚的に表現]

また、本システムではユーザーの手と腕の動きのみを用いてクマの前肢を操作する。触覚刺激がなくても視覚情報と運動（固有受容感覚）の同期だけで身体所有感の錯覚が形成されることが示されており [4]、本研究ではユーザーの手と腕の動きから前肢の運動を推定し、視覚フィードバックを通じてクマの前肢動作を表現する。

IKシステムにおいて肘の横方向への開き（フレア）にペナルティを与えるポールベクトル制約を導入した：

$$\vec{v}_{pole} = \vec{v}_{elbow} - (\vec{v}_{elbow} \cdot \vec{n}_{sagittal}) \vec{n}_{sagittal}$$

ここで、$\vec{v}_{elbow}$は肘の位置ベクトル、$\vec{n}_{sagittal}$は矢状面の法線ベクトルである。この制約により、ユーザーの肘が物理的に開いている場合でも、アバターの前肢は生物学的に正確な軌道を維持し、クマらしい重量感のある動きが視覚的に提示される。

これらのアプローチにより、限られた入力（前肢のみ）から四足歩行全体を表現することが可能となった。視覚運動同期、IKによる運動補完、「クマの前足を使って移動する」という認知的フレーミングの三者が相互作用することで、ユーザーは「クマとして歩いている」という身体化感覚を獲得できる。

5. Results

6. Analysis

7. Discussion

8. Conclusion

9. 参考文献
1 Khan, O., Nam, H., & Kim, K. (2025). Impact of Avatar-Locomotion Congruence on User Experience and Identification in Virtual Reality. IEEE Transactions on Visualization and Computer Graphics, 31(11), 9878–9888.
2 Krekhov, A., Cmentowski, S., & Krüger, J. H. (2019). The Illusion of Animal Body Ownership and Its Potential for Virtual Reality Games. IEEE Conference on Games (CoG), 1–8.
3 Gonzalez-Franco, M., & Lanier, J. (2017). Model of Illusions and Virtual Reality. Frontiers in Psychology, 8, 1125.
4 Sanchez-Vives, M. V., Spanlang, B., Frisoli, A., Bergamasco, M., & Slater, M. (2010). Virtual Hand Illusion Induced by Visuomotor Correlations. PLOS ONE, 5(4), e10381.
5 Kalckert, A., & Ehrsson, H. H. (2012). Moving a Rubber Hand that Feels Like Your Own: A Dissociation of Ownership and Agency. Frontiers in Human Neuroscience, 6, 40.
6 Tao, Y., Wang, C. Y., Wilson, A. D., Ofek, E., & Gonzalez-Franco, M. (2023). Embodying Physics-Aware Avatars in Virtual Reality. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23), Article 254, 1–15.
7 Slater, M., Usoh, M., & Steed, A. (1995). Taking steps: the influence of a walking technique on presence in virtual reality. ACM Trans. Comput.-Hum. Interact., 2(3), 201–219.
8 McCullough, M., et al. (2015). Myo arm: swinging to explore a VE. In Proceedings of the ACM SIGGRAPH Symposium on Applied Perception (SAP '15), 107–113.
9 Jiang, Y., Li, Z., He, M., Lindlbauer, D., & Yan, Y. (2023). HandAvatar: Embodying Non-Humanoid Virtual Avatars through Hands. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23), Article 309, 1–17.
10 Chen, J., Izadi, S., & Fitzgibbon, A. (2012). KinÊtre: animating the world with the human body. In Proceedings of the 25th annual ACM symposium on User interface software and technology (UIST '12), 435–444.
11 Hedlund, M., Bogdan, C., Meixner, G., & Matviienko, A. (2024). Rowing Beyond: Investigating Steering Methods for Rowing-based Locomotion in Virtual Environments. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24), Article 631, 1–17.
12 Guy, M., Normand, J.-M., Jeunet-Kelway, C., & Moreau, G. (2023). The sense of embodiment in Virtual Reality and its assessment methods. Frontiers in Virtual Reality, 4.
13 Ahn, S. J., Bostick, J., Ogle, E., Nowak, K. L., McGillicuddy, K. T., & Bailenson, J. N. (2016). Experiencing Nature: Embodying Animals in Immersive Virtual Environments Increases Inclusion of Nature in Self and Involvement with Nature. Journal of Computer-Mediated Communication, 21(6), 399–419.
14 Seol, Y., O'Sullivan, C., & Lee, J. (2013). Creature features: online motion puppetry for non-human characters. In Proceedings of the 12th ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA '13), 213–221.
15 Krekhov, A., Cmentowski, S., Emmerich, K., & Krüger, J. (2019). Beyond Human: Animals as an Escape from Stereotype Avatars in Virtual Reality Games. In Proceedings of the Annual Symposium on Computer-Human Interaction in Play (CHI PLAY '19), 439–451.
16 Lugrin, J.-L., et al. (2018). Any 'Body' There? Avatar Visibility Effects in a Virtual Reality Game. In 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), 17–24.
17 Dewez, D., Fribourg, R., Argelaguet, F., Hoyet, L., Mestre, D., Slater, M., & Lécuyer, A. (2020). Influence of Locomotion Technique on Sense of Embodiment during Virtual Reality Walking. In Proceedings of the 2020 ACM Symposium on Spatial User Interaction (SUI '20), Article 8, 1–9.
18 Sayyad, E., et al. (2020). Walking and Teleportation in Wide-area Virtual Reality Experiences. In 2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), 608–617.
19 Bowman, D. A., Kruijff, E., Laviola, J. J., & Poupyrev, I. (2004). 3D User Interfaces: Theory and Practice. Addison Wesley.
20 Bozgeyikli, E., Raij, A., Katkoori, S., & Dubey, R. (2016). Point & Teleport Locomotion Technique for Virtual Reality. In Proceedings of the 2016 Annual Symposium on Computer-Human Interaction in Play (CHI PLAY '16), 205–216.
21 Medeiros, D., et al. (2018). Keep My Head on My Shoulders! Why Third-Person is Bad for Navigation in VR. In Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology (VRST '18), Article 16, 1–10.
22 Spangenberger, P., et al. (2022). Becoming a Tree: A Multi-Study Exploration of Virtual Embodiment as a Tool for Environmental Connectedness. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI '22), Article 303, 1–14.
23 Weijs, M. L., et al. (2021). The Development of Sense of Embodiment in Virtual Reality. Psychological Science, 32(5), 743–754.
24 Suk, H. J., et al. (2023). The Influence of Avatar Appearance Similarity on User Embodiment and Presence in VR. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23), Article 567, 1–12.
25 Lan, Y., et al. (2023). The Proteus Effect in Non-Human Avatar Embodiment. Computers in Human Behavior, 142, 107658.
26 Gagnon, C., et al. (2023). Waddle Like a Penguin: Embodiment and Empathy in VR. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23), Article 234, 1–15.
27 Mal, D., et al. (2023). Avatar-Environment Congruence and Its Effect on Plausibility and Proteus Effect. In 2023 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), 574–583.
28 Bailey, J. O., et al. (2016). Virtual Reality and Embodied Cognition. In Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI EA '16), 2468–2474.
29 Ogawa, N., et al. (2020). Feel Like You Own the Virtual Body: Realistic Full-Body Ownership Illusion and Its Effect on Walking-Through-Walls. In 2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), 549–558.
30 Ratan, R., et al. (2024). The Proteus Effect: A Review and Meta-Analysis of Avatar Embodiment Effects. Psychological Bulletin, 150(2), 145–178.
31 Peck, T. C., & Gonzalez-Franco, M. (2021). Avatar Embodiment. A Standardized Questionnaire. Frontiers in Virtual Reality, 1, 575943.
32 Hart, S. G., & Staveland, L. E. (1988). Development of NASA-TLX (Task Load Index): Results of empirical and theoretical research. In P. A. Hancock & N. Meshkati (Eds.), Human Mental Workload (pp. 139–183). North-Holland.
33 Choi, J., Mogami, T., & Medalia, A. (2010). Intrinsic Motivation Inventory: An Adapted Measure for Schizophrenia Research. Schizophrenia Bulletin, 36(5), 966–976. https://doi.org/10.1093/schbul/sbp030
35 Shine, C. L. (2016). Ursidae locomotion: right down to the "bear bones" (Doctoral dissertation). University of Idaho.
36-1 Animal Diversity Web. Ursus arctos (brown bear). University of Michigan Museum of Zoology. https://animaldiversity.org/accounts/Ursus_arctos/ (Accessed December 10, 2025)
36-2 Bartareau, T. M., Cluff, H. D., & Larter, N. C. (2011). Body length and mass growth of the brown bear (Ursus arctos) in northern Canada: model selection based on information theory and ontogeny of sexual size dimorphism. Canadian Journal of Zoology, 89(12), 1128-1135.
40 Amaike, H., Sasaki, M., Tsuzuki, N., Kayano, M., Oishi, M., Yamada, K., Endo, H., Anezaki, T., Matsumoto, N., Nakashita, R., Kuroe, M., Taru, H., Bando, G., Iketani, Y., Nakamura, R., Sato, N., Fukui, D., & Kitamura, N. (2021). Mobility of the forearm skeleton in the Asiatic black (Ursus thibetanus), brown (U. arctos) and polar (U. maritimus) bears. Journal of Veterinary Medical Science, 83(9), 1367-1374.
43 Polly, P. D. (2007). Limbs in mammalian evolution. In B. K. Hall (Ed.), Fins into Limbs: Evolution, Development, and Transformation (pp. 245–268). University of Chicago Press.
44 Shine, C. L., Penberthy, S., Robbins, C. T., Nelson, O. L., & McGowan, C. P. (2015). Grizzly bear (Ursus arctos horribilis) locomotion: gaits and ground reaction forces. Journal of Experimental Biology, 218(19), 3102-3109.
46
[31] Peck & Gonzalez-Franco (2021): Avatar Embodiment標準化質問紙（9実験・443件以上のデータに基づく因子分析、25項目→16項目、4サブスケール：Appearance/Response/Ownership/Multi-Sensory、Cronbach's α = 0.72--0.82）
[32] Hart & Staveland (1988): NASA-TLXの原著論文
[33] Choi et al. (2010): Intrinsic Motivation Inventory（IMI）の心理測定学的検証（内的整合性α=0.92、再検査信頼性ICC=0.77、54項目→21項目、3ドメイン：interest/enjoyment, perceived choice, value/usefulness）
[35] Shine (2016): クマ科の歩行に関する博士論文（蹠行性歩行、食肉目における大型蹠行性動物としての位置づけ）
[36-1] Animal Diversity Web: ヒグマの基本情報（肩高90-150cm等）
[36-2] Bartareau et al. (2011): ヒグマの体長・体重成長、性的二型性の個体発生
[40] Amaike et al. (2021): クマ科の前腕回内・回外運動の研究（亜成体ヒグマで70-80度、成体では40-50度）
[43] Polly (2007): 哺乳類の四肢進化（蹠行性の機能的利点）
[44] Shine et al. (2015): ヒグマの歩容と地面反力（前肢が体重の54-60%を支持、制動力は後肢より大きい）
